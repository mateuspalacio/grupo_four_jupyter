{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "AV3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateuspalacio/grupo_four_jupyter/blob/main/AV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "068f2700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aefdfe3-6203-4c77-b7d0-f12b05d161b7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import confusion_matrix,r2_score,mean_absolute_error,mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from collections import Counter\n",
        "from math import sqrt\n",
        "from datetime import date, timedelta\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from tensorflow.keras.layers import LeakyReLU, Dense\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "transformar_features = True\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.cbook as cbook\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import statsmodels.api as sm\n",
        "import multiprocessing as mp"
      ],
      "id": "068f2700",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fb6a093",
        "outputId": "8ef868db-a119-439c-e2ff-505b46fff2fd"
      },
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU found')\n",
        "else:\n",
        "    print(\"No GPU found\")"
      ],
      "id": "1fb6a093",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "abb0ea5f",
        "outputId": "29247d6b-8133-4739-8763-6a022e56a315"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "id": "abb0ea5f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffe737f4",
        "outputId": "f9ea8cec-935f-4f93-b704-86c46275c9c0"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "id": "ffe737f4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "88cdff94",
        "outputId": "2c0401bb-44d8-4c69-9a31-c1600481b11d"
      },
      "source": [
        "path = os.path.join('VendasTesouroDireto_1.json')\n",
        "values = pd.read_json(path)\n",
        "df_data = pd.DataFrame(values)\n",
        "df_data['Tipo_Titulo'] = df_data['Tipo_Titulo'].astype('str') \n",
        "df_data['PU'] = df_data['PU'].str.replace(',', '.')\n",
        "df_data['Quantidade'] = df_data['Quantidade'].str.replace(',', '.')\n",
        "df_data['Valor'] = df_data['Valor'].str.replace(',', '.')\n",
        "df_data['PU'] = pd.to_numeric(df_data['PU'],errors='coerce')\n",
        "df_data['Quantidade'] = pd.to_numeric(df_data['Quantidade'], errors='coerce')\n",
        "df_data['Valor'] = pd.to_numeric(df_data['Valor'], errors='coerce')\n",
        "\n",
        "df_data['Vencimento_do_Titulo'] = pd.to_datetime(df_data['Vencimento_do_Titulo'],errors='coerce',dayfirst=True)\n",
        " \n",
        "df_data['Data_Venda'] = pd.to_datetime(df_data['Data_Venda'],errors='coerce', dayfirst=True)\n",
        "\n",
        "df_data"
      ],
      "id": "88cdff94",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tipo_Titulo</th>\n",
              "      <th>Vencimento_do_Titulo</th>\n",
              "      <th>Data_Venda</th>\n",
              "      <th>PU</th>\n",
              "      <th>Quantidade</th>\n",
              "      <th>Valor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tesouro IPCA+ com Juros Semestrais</td>\n",
              "      <td>2012-08-15</td>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>1655.206735</td>\n",
              "      <td>38.6</td>\n",
              "      <td>63890.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tesouro IPCA+ com Juros Semestrais</td>\n",
              "      <td>2017-05-15</td>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>1480.154343</td>\n",
              "      <td>571.0</td>\n",
              "      <td>845168.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tesouro Prefixado com Juros Semestrais</td>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>870.303177</td>\n",
              "      <td>283.2</td>\n",
              "      <td>246469.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tesouro Prefixado com Juros Semestrais</td>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>936.285273</td>\n",
              "      <td>29.2</td>\n",
              "      <td>27339.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tesouro Prefixado com Juros Semestrais</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>808.587250</td>\n",
              "      <td>491.8</td>\n",
              "      <td>397663.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66164</th>\n",
              "      <td>Tesouro Prefixado com Juros Semestrais</td>\n",
              "      <td>2010-01-01</td>\n",
              "      <td>2008-08-27</td>\n",
              "      <td>960.339019</td>\n",
              "      <td>110.2</td>\n",
              "      <td>105829.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66165</th>\n",
              "      <td>Tesouro IPCA+ com Juros Semestrais</td>\n",
              "      <td>2010-08-15</td>\n",
              "      <td>2008-08-27</td>\n",
              "      <td>1672.613421</td>\n",
              "      <td>271.2</td>\n",
              "      <td>453612.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66166</th>\n",
              "      <td>Tesouro IPCA+ com Juros Semestrais</td>\n",
              "      <td>2011-05-15</td>\n",
              "      <td>2008-08-27</td>\n",
              "      <td>1677.517573</td>\n",
              "      <td>88.2</td>\n",
              "      <td>147957.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66167</th>\n",
              "      <td>Tesouro Prefixado com Juros Semestrais</td>\n",
              "      <td>2010-07-01</td>\n",
              "      <td>2008-08-27</td>\n",
              "      <td>946.566666</td>\n",
              "      <td>0.6</td>\n",
              "      <td>567.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66168</th>\n",
              "      <td>Tesouro Selic</td>\n",
              "      <td>2014-03-07</td>\n",
              "      <td>2008-08-27</td>\n",
              "      <td>3568.930215</td>\n",
              "      <td>93.0</td>\n",
              "      <td>331910.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66169 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Tipo_Titulo  ...      Valor\n",
              "0          Tesouro IPCA+ com Juros Semestrais  ...   63890.97\n",
              "1          Tesouro IPCA+ com Juros Semestrais  ...  845168.12\n",
              "2      Tesouro Prefixado com Juros Semestrais  ...  246469.85\n",
              "3      Tesouro Prefixado com Juros Semestrais  ...   27339.52\n",
              "4      Tesouro Prefixado com Juros Semestrais  ...  397663.20\n",
              "...                                       ...  ...        ...\n",
              "66164  Tesouro Prefixado com Juros Semestrais  ...  105829.35\n",
              "66165      Tesouro IPCA+ com Juros Semestrais  ...  453612.75\n",
              "66166      Tesouro IPCA+ com Juros Semestrais  ...  147957.04\n",
              "66167  Tesouro Prefixado com Juros Semestrais  ...     567.93\n",
              "66168                           Tesouro Selic  ...  331910.50\n",
              "\n",
              "[66169 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7576dcc",
        "outputId": "5b825720-5701-42c9-c262-7e501671ca53"
      },
      "source": [
        "df_data.info()"
      ],
      "id": "f7576dcc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 66169 entries, 0 to 66168\n",
            "Data columns (total 6 columns):\n",
            " #   Column                Non-Null Count  Dtype         \n",
            "---  ------                --------------  -----         \n",
            " 0   Tipo_Titulo           66169 non-null  object        \n",
            " 1   Vencimento_do_Titulo  66169 non-null  datetime64[ns]\n",
            " 2   Data_Venda            66169 non-null  datetime64[ns]\n",
            " 3   PU                    66169 non-null  float64       \n",
            " 4   Quantidade            66169 non-null  float64       \n",
            " 5   Valor                 66169 non-null  float64       \n",
            "dtypes: datetime64[ns](2), float64(3), object(1)\n",
            "memory usage: 3.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "nj5lDtvf-CYN",
        "outputId": "bf128e81-fa0a-4b37-b88d-5346b496bdd0"
      },
      "source": [
        "aux=df_data.drop(columns=['Vencimento_do_Titulo','PU','Quantidade'])\n",
        "aux.set_index('Data_Venda')\n",
        "data_Value_Per_Day_Selic=pd.DataFrame(aux[aux['Tipo_Titulo']=='Tesouro Selic'].groupby(aux['Data_Venda'].dt.to_period('d'))['Valor'].sum())\n",
        "data_Value_Per_Day_Selic"
      ],
      "id": "nj5lDtvf-CYN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Valor</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data_Venda</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-01-07</th>\n",
              "      <td>15248.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-08</th>\n",
              "      <td>42581.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-09</th>\n",
              "      <td>7840.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-10</th>\n",
              "      <td>252.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-11</th>\n",
              "      <td>6315.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-05</th>\n",
              "      <td>51618710.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-06</th>\n",
              "      <td>64518858.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-09</th>\n",
              "      <td>65513084.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-10</th>\n",
              "      <td>61953661.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-11</th>\n",
              "      <td>65264001.83</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4830 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Valor\n",
              "Data_Venda             \n",
              "2002-01-07     15248.32\n",
              "2002-01-08     42581.98\n",
              "2002-01-09      7840.74\n",
              "2002-01-10       252.18\n",
              "2002-01-11      6315.69\n",
              "...                 ...\n",
              "2021-08-05  51618710.69\n",
              "2021-08-06  64518858.59\n",
              "2021-08-09  65513084.83\n",
              "2021-08-10  61953661.14\n",
              "2021-08-11  65264001.83\n",
              "\n",
              "[4830 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "_JiyPOnm-K_G",
        "outputId": "5a5bceea-f9eb-4b42-cc81-846f3d6f2747"
      },
      "source": [
        "aux=df_data.drop(columns=['Vencimento_do_Titulo','PU','Valor'])\n",
        "aux.set_index('Data_Venda')\n",
        "data_Amount_Per_Day_Selic=pd.DataFrame(aux[aux['Tipo_Titulo']=='Tesouro Selic'].groupby(aux['Data_Venda'].dt.to_period('d'))['Quantidade'].sum())\n",
        "data_Amount_Per_Day_Selic"
      ],
      "id": "_JiyPOnm-K_G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quantidade</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data_Venda</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-01-07</th>\n",
              "      <td>12.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-08</th>\n",
              "      <td>33.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-09</th>\n",
              "      <td>6.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-10</th>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-11</th>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-05</th>\n",
              "      <td>4765.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-06</th>\n",
              "      <td>5953.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-09</th>\n",
              "      <td>6044.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-10</th>\n",
              "      <td>5716.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-11</th>\n",
              "      <td>6021.46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4830 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Quantidade\n",
              "Data_Venda            \n",
              "2002-01-07       12.20\n",
              "2002-01-08       33.80\n",
              "2002-01-09        6.20\n",
              "2002-01-10        0.20\n",
              "2002-01-11        5.00\n",
              "...                ...\n",
              "2021-08-05     4765.41\n",
              "2021-08-06     5953.69\n",
              "2021-08-09     6044.49\n",
              "2021-08-10     5716.93\n",
              "2021-08-11     6021.46\n",
              "\n",
              "[4830 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "tljpUm8j-Znb",
        "outputId": "59238a30-4017-4632-9583-c06494f7ea43"
      },
      "source": [
        "data_day = data_Amount_Per_Day_Selic.merge(data_Value_Per_Day_Selic,on='Data_Venda')\n",
        "data_day['Data_Venda'] = data_day.index\n",
        "data_day"
      ],
      "id": "tljpUm8j-Znb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quantidade</th>\n",
              "      <th>Valor</th>\n",
              "      <th>Data_Venda</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data_Venda</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-01-07</th>\n",
              "      <td>12.20</td>\n",
              "      <td>15248.32</td>\n",
              "      <td>2002-01-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-08</th>\n",
              "      <td>33.80</td>\n",
              "      <td>42581.98</td>\n",
              "      <td>2002-01-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-09</th>\n",
              "      <td>6.20</td>\n",
              "      <td>7840.74</td>\n",
              "      <td>2002-01-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-10</th>\n",
              "      <td>0.20</td>\n",
              "      <td>252.18</td>\n",
              "      <td>2002-01-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-11</th>\n",
              "      <td>5.00</td>\n",
              "      <td>6315.69</td>\n",
              "      <td>2002-01-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-05</th>\n",
              "      <td>4765.41</td>\n",
              "      <td>51618710.69</td>\n",
              "      <td>2021-08-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-06</th>\n",
              "      <td>5953.69</td>\n",
              "      <td>64518858.59</td>\n",
              "      <td>2021-08-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-09</th>\n",
              "      <td>6044.49</td>\n",
              "      <td>65513084.83</td>\n",
              "      <td>2021-08-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-10</th>\n",
              "      <td>5716.93</td>\n",
              "      <td>61953661.14</td>\n",
              "      <td>2021-08-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-11</th>\n",
              "      <td>6021.46</td>\n",
              "      <td>65264001.83</td>\n",
              "      <td>2021-08-11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4830 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Quantidade        Valor  Data_Venda\n",
              "Data_Venda                                     \n",
              "2002-01-07       12.20     15248.32  2002-01-07\n",
              "2002-01-08       33.80     42581.98  2002-01-08\n",
              "2002-01-09        6.20      7840.74  2002-01-09\n",
              "2002-01-10        0.20       252.18  2002-01-10\n",
              "2002-01-11        5.00      6315.69  2002-01-11\n",
              "...                ...          ...         ...\n",
              "2021-08-05     4765.41  51618710.69  2021-08-05\n",
              "2021-08-06     5953.69  64518858.59  2021-08-06\n",
              "2021-08-09     6044.49  65513084.83  2021-08-09\n",
              "2021-08-10     5716.93  61953661.14  2021-08-10\n",
              "2021-08-11     6021.46  65264001.83  2021-08-11\n",
              "\n",
              "[4830 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3a0dd0b0",
        "outputId": "b83aeb1e-dd3a-437e-988f-d17f6f9593e7"
      },
      "source": [
        "pu = df_data['Quantidade']\n",
        "# será se deve ser essas colunas mesmo?\n",
        "df_features = df_data.drop(columns=['Tipo_Titulo', 'Vencimento_do_Titulo', 'Data_Venda', 'Quantidade'])\n",
        "\n",
        "df_features"
      ],
      "id": "3a0dd0b0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PU</th>\n",
              "      <th>Valor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1655.206735</td>\n",
              "      <td>63890.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1480.154343</td>\n",
              "      <td>845168.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>870.303177</td>\n",
              "      <td>246469.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>936.285273</td>\n",
              "      <td>27339.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>808.587250</td>\n",
              "      <td>397663.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66164</th>\n",
              "      <td>960.339019</td>\n",
              "      <td>105829.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66165</th>\n",
              "      <td>1672.613421</td>\n",
              "      <td>453612.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66166</th>\n",
              "      <td>1677.517573</td>\n",
              "      <td>147957.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66167</th>\n",
              "      <td>946.566666</td>\n",
              "      <td>567.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66168</th>\n",
              "      <td>3568.930215</td>\n",
              "      <td>331910.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66169 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                PU      Valor\n",
              "0      1655.206735   63890.97\n",
              "1      1480.154343  845168.12\n",
              "2       870.303177  246469.85\n",
              "3       936.285273   27339.52\n",
              "4       808.587250  397663.20\n",
              "...            ...        ...\n",
              "66164   960.339019  105829.35\n",
              "66165  1672.613421  453612.75\n",
              "66166  1677.517573  147957.04\n",
              "66167   946.566666     567.93\n",
              "66168  3568.930215  331910.50\n",
              "\n",
              "[66169 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5b963c8"
      },
      "source": [
        "df_dados_c0=df_data[df_data['Tipo_Titulo']=='Tesouro Prefixado com Juros Semestrais']\n",
        "df_dados_c1=df_data[df_data['Tipo_Titulo']=='Tesouro Selic']\n",
        "df_dados_c2=df_data[df_data['Tipo_Titulo']=='Tesouro Prefixado']\n",
        "df_dados_c3=df_data[df_data['Tipo_Titulo']=='Tesouro Prefixado IPCA+']\n",
        "df_dados_c4=df_data[df_data['Tipo_Titulo']=='Tesouro IGPM+ com Juros Semestrais']\n",
        "df_dados_c5=df_data[df_data['Tipo_Titulo']=='Tesouro Prefixado IPCA+ com Juros Semestrais']"
      ],
      "id": "e5b963c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "bcf1e968",
        "outputId": "638e9c0a-ad6d-4d50-e153-cd14da7a008d"
      },
      "source": [
        "data_day['d_semana'] = data_day['Data_Venda'].dt.dayofweek\n",
        "data_day['d_mes'] = data_day['Data_Venda'].dt.strftime(\"%d\")\n",
        "data_day['d_ano'] = data_day['Data_Venda'].dt.strftime(\"%j\")\n",
        "\n",
        "data_day['d_semana'] = data_day['d_semana'].astype(int)\n",
        "data_day['d_mes'] = data_day['d_mes'].astype(int)\n",
        "data_day['d_ano'] = data_day['d_ano'].astype(int)\n",
        "\n",
        "data_day"
      ],
      "id": "bcf1e968",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quantidade</th>\n",
              "      <th>Valor</th>\n",
              "      <th>Data_Venda</th>\n",
              "      <th>d_semana</th>\n",
              "      <th>d_mes</th>\n",
              "      <th>d_ano</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data_Venda</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-01-07</th>\n",
              "      <td>12.20</td>\n",
              "      <td>15248.32</td>\n",
              "      <td>2002-01-07</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-08</th>\n",
              "      <td>33.80</td>\n",
              "      <td>42581.98</td>\n",
              "      <td>2002-01-08</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-09</th>\n",
              "      <td>6.20</td>\n",
              "      <td>7840.74</td>\n",
              "      <td>2002-01-09</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-10</th>\n",
              "      <td>0.20</td>\n",
              "      <td>252.18</td>\n",
              "      <td>2002-01-10</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-11</th>\n",
              "      <td>5.00</td>\n",
              "      <td>6315.69</td>\n",
              "      <td>2002-01-11</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-05</th>\n",
              "      <td>4765.41</td>\n",
              "      <td>51618710.69</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-06</th>\n",
              "      <td>5953.69</td>\n",
              "      <td>64518858.59</td>\n",
              "      <td>2021-08-06</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-09</th>\n",
              "      <td>6044.49</td>\n",
              "      <td>65513084.83</td>\n",
              "      <td>2021-08-09</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-10</th>\n",
              "      <td>5716.93</td>\n",
              "      <td>61953661.14</td>\n",
              "      <td>2021-08-10</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-11</th>\n",
              "      <td>6021.46</td>\n",
              "      <td>65264001.83</td>\n",
              "      <td>2021-08-11</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4830 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Quantidade        Valor  Data_Venda  d_semana  d_mes  d_ano\n",
              "Data_Venda                                                             \n",
              "2002-01-07       12.20     15248.32  2002-01-07         0      7      7\n",
              "2002-01-08       33.80     42581.98  2002-01-08         1      8      8\n",
              "2002-01-09        6.20      7840.74  2002-01-09         2      9      9\n",
              "2002-01-10        0.20       252.18  2002-01-10         3     10     10\n",
              "2002-01-11        5.00      6315.69  2002-01-11         4     11     11\n",
              "...                ...          ...         ...       ...    ...    ...\n",
              "2021-08-05     4765.41  51618710.69  2021-08-05         3      5    217\n",
              "2021-08-06     5953.69  64518858.59  2021-08-06         4      6    218\n",
              "2021-08-09     6044.49  65513084.83  2021-08-09         0      9    221\n",
              "2021-08-10     5716.93  61953661.14  2021-08-10         1     10    222\n",
              "2021-08-11     6021.46  65264001.83  2021-08-11         2     11    223\n",
              "\n",
              "[4830 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "dcba7a59",
        "outputId": "f8948b01-d447-4281-ea10-c8f4688c6066"
      },
      "source": [
        "feature_names = ['Quantidade', 'Valor','d_semana','d_mes','d_ano']\n",
        "data_day_features=data_day.drop(columns=['Data_Venda'])\n",
        "#data_day = data_day.drop(columns=['Tipo_Titulo','Vencimento_do_Titulo'])\n",
        "data_day_features"
      ],
      "id": "dcba7a59",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quantidade</th>\n",
              "      <th>Valor</th>\n",
              "      <th>d_semana</th>\n",
              "      <th>d_mes</th>\n",
              "      <th>d_ano</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data_Venda</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-01-07</th>\n",
              "      <td>12.20</td>\n",
              "      <td>15248.32</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-08</th>\n",
              "      <td>33.80</td>\n",
              "      <td>42581.98</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-09</th>\n",
              "      <td>6.20</td>\n",
              "      <td>7840.74</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-10</th>\n",
              "      <td>0.20</td>\n",
              "      <td>252.18</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-11</th>\n",
              "      <td>5.00</td>\n",
              "      <td>6315.69</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-05</th>\n",
              "      <td>4765.41</td>\n",
              "      <td>51618710.69</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-06</th>\n",
              "      <td>5953.69</td>\n",
              "      <td>64518858.59</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-09</th>\n",
              "      <td>6044.49</td>\n",
              "      <td>65513084.83</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-10</th>\n",
              "      <td>5716.93</td>\n",
              "      <td>61953661.14</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-11</th>\n",
              "      <td>6021.46</td>\n",
              "      <td>65264001.83</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4830 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Quantidade        Valor  d_semana  d_mes  d_ano\n",
              "Data_Venda                                                 \n",
              "2002-01-07       12.20     15248.32         0      7      7\n",
              "2002-01-08       33.80     42581.98         1      8      8\n",
              "2002-01-09        6.20      7840.74         2      9      9\n",
              "2002-01-10        0.20       252.18         3     10     10\n",
              "2002-01-11        5.00      6315.69         4     11     11\n",
              "...                ...          ...       ...    ...    ...\n",
              "2021-08-05     4765.41  51618710.69         3      5    217\n",
              "2021-08-06     5953.69  64518858.59         4      6    218\n",
              "2021-08-09     6044.49  65513084.83         0      9    221\n",
              "2021-08-10     5716.93  61953661.14         1     10    222\n",
              "2021-08-11     6021.46  65264001.83         2     11    223\n",
              "\n",
              "[4830 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "637070a7"
      },
      "source": [
        "# aplicando escala pros valores ficarem entre 0 e 1\n",
        "if(transformar_features): \n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "    data_day_features[feature_names] = scaler.fit_transform(data_day_features[feature_names])\n",
        "\n",
        "    data_day_features"
      ],
      "id": "637070a7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "b1ff7204",
        "outputId": "8cc1b846-d659-4ede-b0a8-999154cdbbb3"
      },
      "source": [
        "data_day_features"
      ],
      "id": "b1ff7204",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quantidade</th>\n",
              "      <th>Valor</th>\n",
              "      <th>d_semana</th>\n",
              "      <th>d_mes</th>\n",
              "      <th>d_ano</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data_Venda</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-01-07</th>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.013774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-08</th>\n",
              "      <td>0.000960</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.016529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-09</th>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.019284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.022039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-11</th>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.024793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-05</th>\n",
              "      <td>0.136202</td>\n",
              "      <td>0.146113</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.592287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-06</th>\n",
              "      <td>0.170167</td>\n",
              "      <td>0.182628</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.595041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-09</th>\n",
              "      <td>0.172762</td>\n",
              "      <td>0.185443</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.603306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-10</th>\n",
              "      <td>0.163399</td>\n",
              "      <td>0.175367</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.606061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-11</th>\n",
              "      <td>0.172104</td>\n",
              "      <td>0.184737</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.608815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4830 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Quantidade     Valor  d_semana     d_mes     d_ano\n",
              "Data_Venda                                                    \n",
              "2002-01-07    0.000343  0.000042      0.00  0.200000  0.013774\n",
              "2002-01-08    0.000960  0.000120      0.25  0.233333  0.016529\n",
              "2002-01-09    0.000171  0.000021      0.50  0.266667  0.019284\n",
              "2002-01-10    0.000000  0.000000      0.75  0.300000  0.022039\n",
              "2002-01-11    0.000137  0.000017      1.00  0.333333  0.024793\n",
              "...                ...       ...       ...       ...       ...\n",
              "2021-08-05    0.136202  0.146113      0.75  0.133333  0.592287\n",
              "2021-08-06    0.170167  0.182628      1.00  0.166667  0.595041\n",
              "2021-08-09    0.172762  0.185443      0.00  0.266667  0.603306\n",
              "2021-08-10    0.163399  0.175367      0.25  0.300000  0.606061\n",
              "2021-08-11    0.172104  0.184737      0.50  0.333333  0.608815\n",
              "\n",
              "[4830 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "5925e6ce",
        "outputId": "632b67ab-6db7-46a3-f458-72feedc5fa92"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(range(len(data_day)),data_day['Quantidade'], 'b--')\n",
        "#plt.xlim(4000,4300)\n",
        "plt.show()"
      ],
      "id": "5925e6ce",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f97715f",
        "outputId": "c014dbb8-e571-4e47-a4aa-e73c53ef345e"
      },
      "source": [
        "time_steps = 365\n",
        "test_size = 120\n",
        "\n",
        "train_size = int(len(data_day_features)-(test_size))\n",
        "train, test = data_day_features.iloc[0:train_size], data_day_features.iloc[(train_size-time_steps):len(data_day_features)]\n",
        "\n",
        "print(len(train), len(test))"
      ],
      "id": "5f97715f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4710 485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65b40399"
      },
      "source": [
        "def create_dataset(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        v = X.iloc[i:(i + time_steps),0].to_numpy()\n",
        "        v = np.append(v,X.iloc[i + time_steps,1])#price\n",
        "        v = np.append(v,X.iloc[i + time_steps,2])#d_semana\n",
        "        v = np.append(v,X.iloc[i + time_steps,3])#d_mes\n",
        "        v = np.append(v,X.iloc[i + time_steps,4])#d_ano\n",
        "        Xs.append([v])\n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_train, y_train = create_dataset(train, train['Quantidade'], time_steps)\n",
        "X_test, y_test = create_dataset(test, test['Quantidade'], time_steps)\n",
        "\n"
      ],
      "id": "65b40399",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5235545d",
        "outputId": "a22bcc35-bd6d-40bc-871c-730b33918ebc"
      },
      "source": [
        "print(len(y_train),len(y_test))"
      ],
      "id": "5235545d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4345 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EswPohLFqHk",
        "outputId": "1d32033b-eb26-46c8-c334-0c96ab0e1897"
      },
      "source": [
        "nsamples, nx, ny = X_train.shape\n",
        "d2_xtrain_dataset = X_train.reshape((nsamples,nx*ny))\n",
        "d2_xtrain_dataset\n"
      ],
      "id": "3EswPohLFqHk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.42991988e-04, 9.60377566e-04, 1.71495994e-04, ...,\n",
              "        0.00000000e+00, 4.33333333e-01, 5.31680441e-01],\n",
              "       [9.60377566e-04, 1.71495994e-04, 0.00000000e+00, ...,\n",
              "        2.50000000e-01, 4.66666667e-01, 5.34435262e-01],\n",
              "       [1.71495994e-04, 0.00000000e+00, 1.37196795e-04, ...,\n",
              "        5.00000000e-01, 5.00000000e-01, 5.37190083e-01],\n",
              "       ...,\n",
              "       [1.20469362e-01, 1.13626672e-01, 1.37280256e-01, ...,\n",
              "        1.00000000e+00, 3.66666667e-01, 1.12947658e-01],\n",
              "       [1.13626672e-01, 1.37280256e-01, 1.10667508e-01, ...,\n",
              "        5.00000000e-01, 5.33333333e-01, 1.26721763e-01],\n",
              "       [1.37280256e-01, 1.10667508e-01, 1.21424880e-01, ...,\n",
              "        7.50000000e-01, 5.66666667e-01, 1.29476584e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJIr-gPTDYgM"
      },
      "source": [
        "parameters = [{\n",
        "'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], \n",
        "'C': [1,2,3,300,500],\n",
        "'max_iter': [1000,100000]}]"
      ],
      "id": "tJIr-gPTDYgM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "h1FdD9uVDaJR",
        "outputId": "d753f8b7-64df-428d-81fb-0aee59a39e17"
      },
      "source": [
        "clf = GridSearchCV(\n",
        "        SVR(), parameters, scoring='r2'\n",
        "    )\n",
        "x_fit = clf.fit(d2_xtrain_dataset, y_train)"
      ],
      "id": "h1FdD9uVDaJR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b2636f242a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     )\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2_xtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPdCDCqXIqBU"
      },
      "source": [
        "d2_xtrain_dataset"
      ],
      "id": "xPdCDCqXIqBU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8dc6ec6"
      },
      "source": [
        "def getModel():\n",
        "    model = tf.keras.Sequential()\n",
        "    #leaky_relu = LeakyReLU(alpha=0.01)\n",
        "    \n",
        "    # MLP    \n",
        "    #model.add(tf.keras.layers.Dense(300, activation=\"selu\", input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    #model.add(tf.keras.layers.Dense(3000, activation=\"selu\", input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    #model.add(tf.keras.layers.Dense(1000, activation=\"selu\")) \n",
        "    model.add(tf.keras.layers.Dense(900, activation=\"selu\",input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(tf.keras.layers.Dense(300, activation=\"selu\"))\n",
        "    model.add(tf.keras.layers.Dense(100, activation=\"selu\"))\n",
        "    model.add(tf.keras.layers.Dense(90, activation=\"selu\"))\n",
        "    model.add(tf.keras.layers.Dense(30, activation=\"selu\"))\n",
        "    model.add(tf.keras.layers.Dense(10, activation=\"selu\"))\n",
        "    \n",
        "    # Vanilla LSTM\n",
        "    # model.add(tf.keras.layers.LSTM(100, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "        \n",
        "    # Stacked LSTM\n",
        "#     model.add(tf.keras.layers.LSTM(3000, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "#     model.add(tf.keras.layers.LSTM(1000, activation='relu', return_sequences=True))\n",
        "#     model.add(tf.keras.layers.LSTM(300, activation='relu', return_sequences=True))\n",
        "#     model.add(tf.keras.layers.LSTM(100, activation='relu', return_sequences=True))\n",
        "#     model.add(tf.keras.layers.LSTM(30, activation='relu', return_sequences=True))\n",
        "#     model.add(tf.keras.layers.LSTM(10, activation='relu'))\n",
        "    \n",
        "    # Bidirectional LSTM\n",
        "#     model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, activation='relu'), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=1,activation='softplus'))\n",
        "    \n",
        "    return model"
      ],
      "id": "d8dc6ec6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e46f43ed"
      },
      "source": [
        "model = getModel()\n",
        "\n",
        "model.compile(\n",
        "  loss='mean_squared_error',\n",
        "  optimizer=tf.keras.optimizers.Adam(0.001)\n",
        ")"
      ],
      "id": "e46f43ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "128b1068",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d65778-9f95-45eb-cef6-68093c44f540"
      },
      "source": [
        "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')]\n",
        "\n",
        "callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, restore_best_weights=True))\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=1000, #1000\n",
        "    batch_size=50, # 30\n",
        "    validation_split=0.4,\n",
        "    #callbacks=callbacks,\n",
        "    shuffle=False\n",
        ")"
      ],
      "id": "128b1068",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.1607e-05 - val_loss: 0.0029\n",
            "Epoch 2/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.1182e-05 - val_loss: 0.0029\n",
            "Epoch 3/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0983e-05 - val_loss: 0.0029\n",
            "Epoch 4/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0892e-05 - val_loss: 0.0029\n",
            "Epoch 5/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0846e-05 - val_loss: 0.0030\n",
            "Epoch 6/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0820e-05 - val_loss: 0.0030\n",
            "Epoch 7/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0804e-05 - val_loss: 0.0030\n",
            "Epoch 8/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0793e-05 - val_loss: 0.0030\n",
            "Epoch 9/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0785e-05 - val_loss: 0.0030\n",
            "Epoch 10/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0778e-05 - val_loss: 0.0029\n",
            "Epoch 11/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0772e-05 - val_loss: 0.0029\n",
            "Epoch 12/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0767e-05 - val_loss: 0.0029\n",
            "Epoch 13/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0761e-05 - val_loss: 0.0029\n",
            "Epoch 14/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0756e-05 - val_loss: 0.0029\n",
            "Epoch 15/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0751e-05 - val_loss: 0.0029\n",
            "Epoch 16/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0746e-05 - val_loss: 0.0029\n",
            "Epoch 17/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0741e-05 - val_loss: 0.0029\n",
            "Epoch 18/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0736e-05 - val_loss: 0.0029\n",
            "Epoch 19/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0730e-05 - val_loss: 0.0029\n",
            "Epoch 20/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0725e-05 - val_loss: 0.0029\n",
            "Epoch 21/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0720e-05 - val_loss: 0.0029\n",
            "Epoch 22/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0714e-05 - val_loss: 0.0029\n",
            "Epoch 23/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0709e-05 - val_loss: 0.0029\n",
            "Epoch 24/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0703e-05 - val_loss: 0.0029\n",
            "Epoch 25/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0697e-05 - val_loss: 0.0029\n",
            "Epoch 26/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0691e-05 - val_loss: 0.0029\n",
            "Epoch 27/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0685e-05 - val_loss: 0.0029\n",
            "Epoch 28/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0679e-05 - val_loss: 0.0029\n",
            "Epoch 29/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0673e-05 - val_loss: 0.0029\n",
            "Epoch 30/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0667e-05 - val_loss: 0.0028\n",
            "Epoch 31/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0661e-05 - val_loss: 0.0028\n",
            "Epoch 32/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0655e-05 - val_loss: 0.0028\n",
            "Epoch 33/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0648e-05 - val_loss: 0.0028\n",
            "Epoch 34/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0642e-05 - val_loss: 0.0028\n",
            "Epoch 35/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0635e-05 - val_loss: 0.0028\n",
            "Epoch 36/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0628e-05 - val_loss: 0.0028\n",
            "Epoch 37/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0622e-05 - val_loss: 0.0028\n",
            "Epoch 38/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0615e-05 - val_loss: 0.0028\n",
            "Epoch 39/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0608e-05 - val_loss: 0.0028\n",
            "Epoch 40/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0601e-05 - val_loss: 0.0028\n",
            "Epoch 41/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0594e-05 - val_loss: 0.0028\n",
            "Epoch 42/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0586e-05 - val_loss: 0.0028\n",
            "Epoch 43/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0579e-05 - val_loss: 0.0028\n",
            "Epoch 44/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0572e-05 - val_loss: 0.0028\n",
            "Epoch 45/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0564e-05 - val_loss: 0.0028\n",
            "Epoch 46/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0556e-05 - val_loss: 0.0028\n",
            "Epoch 47/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0549e-05 - val_loss: 0.0028\n",
            "Epoch 48/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0541e-05 - val_loss: 0.0028\n",
            "Epoch 49/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0533e-05 - val_loss: 0.0028\n",
            "Epoch 50/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0525e-05 - val_loss: 0.0028\n",
            "Epoch 51/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0517e-05 - val_loss: 0.0028\n",
            "Epoch 52/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0509e-05 - val_loss: 0.0028\n",
            "Epoch 53/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0500e-05 - val_loss: 0.0028\n",
            "Epoch 54/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0492e-05 - val_loss: 0.0028\n",
            "Epoch 55/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0483e-05 - val_loss: 0.0028\n",
            "Epoch 56/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0474e-05 - val_loss: 0.0028\n",
            "Epoch 57/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0466e-05 - val_loss: 0.0029\n",
            "Epoch 58/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0457e-05 - val_loss: 0.0029\n",
            "Epoch 59/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0448e-05 - val_loss: 0.0029\n",
            "Epoch 60/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0439e-05 - val_loss: 0.0029\n",
            "Epoch 61/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0430e-05 - val_loss: 0.0029\n",
            "Epoch 62/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0420e-05 - val_loss: 0.0029\n",
            "Epoch 63/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0411e-05 - val_loss: 0.0029\n",
            "Epoch 64/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0402e-05 - val_loss: 0.0029\n",
            "Epoch 65/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0392e-05 - val_loss: 0.0029\n",
            "Epoch 66/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0383e-05 - val_loss: 0.0030\n",
            "Epoch 67/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0373e-05 - val_loss: 0.0030\n",
            "Epoch 68/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0364e-05 - val_loss: 0.0030\n",
            "Epoch 69/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0354e-05 - val_loss: 0.0030\n",
            "Epoch 70/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0344e-05 - val_loss: 0.0030\n",
            "Epoch 71/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0334e-05 - val_loss: 0.0031\n",
            "Epoch 72/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0324e-05 - val_loss: 0.0031\n",
            "Epoch 73/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0315e-05 - val_loss: 0.0031\n",
            "Epoch 74/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0305e-05 - val_loss: 0.0031\n",
            "Epoch 75/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0295e-05 - val_loss: 0.0031\n",
            "Epoch 76/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0284e-05 - val_loss: 0.0032\n",
            "Epoch 77/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0274e-05 - val_loss: 0.0032\n",
            "Epoch 78/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0264e-05 - val_loss: 0.0032\n",
            "Epoch 79/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 3.0254e-05 - val_loss: 0.0033\n",
            "Epoch 80/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0244e-05 - val_loss: 0.0033\n",
            "Epoch 81/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0233e-05 - val_loss: 0.0033\n",
            "Epoch 82/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0223e-05 - val_loss: 0.0034\n",
            "Epoch 83/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0213e-05 - val_loss: 0.0034\n",
            "Epoch 84/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0202e-05 - val_loss: 0.0034\n",
            "Epoch 85/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0191e-05 - val_loss: 0.0035\n",
            "Epoch 86/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0181e-05 - val_loss: 0.0035\n",
            "Epoch 87/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0170e-05 - val_loss: 0.0036\n",
            "Epoch 88/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0159e-05 - val_loss: 0.0036\n",
            "Epoch 89/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0148e-05 - val_loss: 0.0037\n",
            "Epoch 90/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0138e-05 - val_loss: 0.0037\n",
            "Epoch 91/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0127e-05 - val_loss: 0.0038\n",
            "Epoch 92/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0116e-05 - val_loss: 0.0038\n",
            "Epoch 93/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0105e-05 - val_loss: 0.0039\n",
            "Epoch 94/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0094e-05 - val_loss: 0.0039\n",
            "Epoch 95/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0084e-05 - val_loss: 0.0040\n",
            "Epoch 96/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0072e-05 - val_loss: 0.0040\n",
            "Epoch 97/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0061e-05 - val_loss: 0.0041\n",
            "Epoch 98/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0050e-05 - val_loss: 0.0042\n",
            "Epoch 99/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0039e-05 - val_loss: 0.0042\n",
            "Epoch 100/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0028e-05 - val_loss: 0.0043\n",
            "Epoch 101/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0017e-05 - val_loss: 0.0044\n",
            "Epoch 102/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 3.0006e-05 - val_loss: 0.0044\n",
            "Epoch 103/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9994e-05 - val_loss: 0.0045\n",
            "Epoch 104/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9983e-05 - val_loss: 0.0046\n",
            "Epoch 105/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9972e-05 - val_loss: 0.0046\n",
            "Epoch 106/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9960e-05 - val_loss: 0.0047\n",
            "Epoch 107/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9949e-05 - val_loss: 0.0048\n",
            "Epoch 108/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9938e-05 - val_loss: 0.0049\n",
            "Epoch 109/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9926e-05 - val_loss: 0.0049\n",
            "Epoch 110/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9915e-05 - val_loss: 0.0050\n",
            "Epoch 111/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9903e-05 - val_loss: 0.0051\n",
            "Epoch 112/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9892e-05 - val_loss: 0.0052\n",
            "Epoch 113/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9880e-05 - val_loss: 0.0053\n",
            "Epoch 114/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9869e-05 - val_loss: 0.0054\n",
            "Epoch 115/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9857e-05 - val_loss: 0.0055\n",
            "Epoch 116/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9846e-05 - val_loss: 0.0056\n",
            "Epoch 117/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9834e-05 - val_loss: 0.0057\n",
            "Epoch 118/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9823e-05 - val_loss: 0.0058\n",
            "Epoch 119/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9811e-05 - val_loss: 0.0059\n",
            "Epoch 120/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9800e-05 - val_loss: 0.0060\n",
            "Epoch 121/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9789e-05 - val_loss: 0.0061\n",
            "Epoch 122/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9778e-05 - val_loss: 0.0062\n",
            "Epoch 123/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9767e-05 - val_loss: 0.0063\n",
            "Epoch 124/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9755e-05 - val_loss: 0.0064\n",
            "Epoch 125/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9745e-05 - val_loss: 0.0065\n",
            "Epoch 126/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9734e-05 - val_loss: 0.0066\n",
            "Epoch 127/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9723e-05 - val_loss: 0.0067\n",
            "Epoch 128/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9712e-05 - val_loss: 0.0068\n",
            "Epoch 129/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9701e-05 - val_loss: 0.0069\n",
            "Epoch 130/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9691e-05 - val_loss: 0.0070\n",
            "Epoch 131/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9680e-05 - val_loss: 0.0071\n",
            "Epoch 132/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9669e-05 - val_loss: 0.0072\n",
            "Epoch 133/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9659e-05 - val_loss: 0.0074\n",
            "Epoch 134/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9648e-05 - val_loss: 0.0075\n",
            "Epoch 135/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9638e-05 - val_loss: 0.0076\n",
            "Epoch 136/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9628e-05 - val_loss: 0.0077\n",
            "Epoch 137/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9618e-05 - val_loss: 0.0078\n",
            "Epoch 138/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9608e-05 - val_loss: 0.0079\n",
            "Epoch 139/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9598e-05 - val_loss: 0.0080\n",
            "Epoch 140/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9588e-05 - val_loss: 0.0081\n",
            "Epoch 141/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9578e-05 - val_loss: 0.0082\n",
            "Epoch 142/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9569e-05 - val_loss: 0.0084\n",
            "Epoch 143/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9559e-05 - val_loss: 0.0085\n",
            "Epoch 144/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9549e-05 - val_loss: 0.0086\n",
            "Epoch 145/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9539e-05 - val_loss: 0.0087\n",
            "Epoch 146/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9529e-05 - val_loss: 0.0088\n",
            "Epoch 147/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9519e-05 - val_loss: 0.0090\n",
            "Epoch 148/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9509e-05 - val_loss: 0.0091\n",
            "Epoch 149/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9500e-05 - val_loss: 0.0092\n",
            "Epoch 150/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9490e-05 - val_loss: 0.0093\n",
            "Epoch 151/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9481e-05 - val_loss: 0.0095\n",
            "Epoch 152/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9472e-05 - val_loss: 0.0096\n",
            "Epoch 153/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9463e-05 - val_loss: 0.0097\n",
            "Epoch 154/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9454e-05 - val_loss: 0.0098\n",
            "Epoch 155/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9445e-05 - val_loss: 0.0100\n",
            "Epoch 156/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9436e-05 - val_loss: 0.0101\n",
            "Epoch 157/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9427e-05 - val_loss: 0.0102\n",
            "Epoch 158/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9419e-05 - val_loss: 0.0104\n",
            "Epoch 159/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9410e-05 - val_loss: 0.0105\n",
            "Epoch 160/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9402e-05 - val_loss: 0.0106\n",
            "Epoch 161/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9394e-05 - val_loss: 0.0107\n",
            "Epoch 162/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9385e-05 - val_loss: 0.0109\n",
            "Epoch 163/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9377e-05 - val_loss: 0.0110\n",
            "Epoch 164/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9369e-05 - val_loss: 0.0111\n",
            "Epoch 165/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9361e-05 - val_loss: 0.0113\n",
            "Epoch 166/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9353e-05 - val_loss: 0.0114\n",
            "Epoch 167/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9345e-05 - val_loss: 0.0115\n",
            "Epoch 168/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9337e-05 - val_loss: 0.0116\n",
            "Epoch 169/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9329e-05 - val_loss: 0.0118\n",
            "Epoch 170/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9321e-05 - val_loss: 0.0119\n",
            "Epoch 171/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9313e-05 - val_loss: 0.0120\n",
            "Epoch 172/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9306e-05 - val_loss: 0.0121\n",
            "Epoch 173/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9298e-05 - val_loss: 0.0122\n",
            "Epoch 174/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9290e-05 - val_loss: 0.0124\n",
            "Epoch 175/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9282e-05 - val_loss: 0.0125\n",
            "Epoch 176/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9274e-05 - val_loss: 0.0126\n",
            "Epoch 177/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9267e-05 - val_loss: 0.0127\n",
            "Epoch 178/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9259e-05 - val_loss: 0.0128\n",
            "Epoch 179/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9251e-05 - val_loss: 0.0129\n",
            "Epoch 180/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9244e-05 - val_loss: 0.0130\n",
            "Epoch 181/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9236e-05 - val_loss: 0.0131\n",
            "Epoch 182/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9229e-05 - val_loss: 0.0132\n",
            "Epoch 183/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9221e-05 - val_loss: 0.0133\n",
            "Epoch 184/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9214e-05 - val_loss: 0.0134\n",
            "Epoch 185/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9206e-05 - val_loss: 0.0136\n",
            "Epoch 186/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9198e-05 - val_loss: 0.0137\n",
            "Epoch 187/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9191e-05 - val_loss: 0.0138\n",
            "Epoch 188/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9183e-05 - val_loss: 0.0139\n",
            "Epoch 189/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9176e-05 - val_loss: 0.0140\n",
            "Epoch 190/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9168e-05 - val_loss: 0.0142\n",
            "Epoch 191/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9160e-05 - val_loss: 0.0143\n",
            "Epoch 192/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9153e-05 - val_loss: 0.0144\n",
            "Epoch 193/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9145e-05 - val_loss: 0.0145\n",
            "Epoch 194/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9138e-05 - val_loss: 0.0146\n",
            "Epoch 195/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9131e-05 - val_loss: 0.0147\n",
            "Epoch 196/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9123e-05 - val_loss: 0.0148\n",
            "Epoch 197/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9116e-05 - val_loss: 0.0149\n",
            "Epoch 198/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9109e-05 - val_loss: 0.0150\n",
            "Epoch 199/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9102e-05 - val_loss: 0.0151\n",
            "Epoch 200/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9095e-05 - val_loss: 0.0151\n",
            "Epoch 201/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9088e-05 - val_loss: 0.0152\n",
            "Epoch 202/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9081e-05 - val_loss: 0.0153\n",
            "Epoch 203/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9074e-05 - val_loss: 0.0154\n",
            "Epoch 204/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9067e-05 - val_loss: 0.0155\n",
            "Epoch 205/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9059e-05 - val_loss: 0.0155\n",
            "Epoch 206/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9053e-05 - val_loss: 0.0156\n",
            "Epoch 207/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9045e-05 - val_loss: 0.0157\n",
            "Epoch 208/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.9039e-05 - val_loss: 0.0158\n",
            "Epoch 209/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9032e-05 - val_loss: 0.0159\n",
            "Epoch 210/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9025e-05 - val_loss: 0.0160\n",
            "Epoch 211/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9018e-05 - val_loss: 0.0161\n",
            "Epoch 212/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9011e-05 - val_loss: 0.0162\n",
            "Epoch 213/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.9004e-05 - val_loss: 0.0163\n",
            "Epoch 214/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8997e-05 - val_loss: 0.0163\n",
            "Epoch 215/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8991e-05 - val_loss: 0.0164\n",
            "Epoch 216/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8984e-05 - val_loss: 0.0165\n",
            "Epoch 217/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8977e-05 - val_loss: 0.0166\n",
            "Epoch 218/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8970e-05 - val_loss: 0.0166\n",
            "Epoch 219/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8963e-05 - val_loss: 0.0167\n",
            "Epoch 220/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8957e-05 - val_loss: 0.0168\n",
            "Epoch 221/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8950e-05 - val_loss: 0.0168\n",
            "Epoch 222/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8943e-05 - val_loss: 0.0169\n",
            "Epoch 223/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8937e-05 - val_loss: 0.0170\n",
            "Epoch 224/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8930e-05 - val_loss: 0.0170\n",
            "Epoch 225/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8923e-05 - val_loss: 0.0171\n",
            "Epoch 226/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8917e-05 - val_loss: 0.0172\n",
            "Epoch 227/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8910e-05 - val_loss: 0.0172\n",
            "Epoch 228/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8904e-05 - val_loss: 0.0173\n",
            "Epoch 229/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8897e-05 - val_loss: 0.0173\n",
            "Epoch 230/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8891e-05 - val_loss: 0.0174\n",
            "Epoch 231/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8884e-05 - val_loss: 0.0175\n",
            "Epoch 232/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8878e-05 - val_loss: 0.0175\n",
            "Epoch 233/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8872e-05 - val_loss: 0.0175\n",
            "Epoch 234/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8865e-05 - val_loss: 0.0176\n",
            "Epoch 235/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8859e-05 - val_loss: 0.0176\n",
            "Epoch 236/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8852e-05 - val_loss: 0.0177\n",
            "Epoch 237/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8846e-05 - val_loss: 0.0177\n",
            "Epoch 238/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8840e-05 - val_loss: 0.0177\n",
            "Epoch 239/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8833e-05 - val_loss: 0.0177\n",
            "Epoch 240/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8827e-05 - val_loss: 0.0178\n",
            "Epoch 241/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8821e-05 - val_loss: 0.0178\n",
            "Epoch 242/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8814e-05 - val_loss: 0.0178\n",
            "Epoch 243/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8808e-05 - val_loss: 0.0178\n",
            "Epoch 244/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8802e-05 - val_loss: 0.0178\n",
            "Epoch 245/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8795e-05 - val_loss: 0.0178\n",
            "Epoch 246/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8789e-05 - val_loss: 0.0178\n",
            "Epoch 247/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8783e-05 - val_loss: 0.0178\n",
            "Epoch 248/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8777e-05 - val_loss: 0.0178\n",
            "Epoch 249/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8770e-05 - val_loss: 0.0179\n",
            "Epoch 250/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8764e-05 - val_loss: 0.0179\n",
            "Epoch 251/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8758e-05 - val_loss: 0.0179\n",
            "Epoch 252/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8752e-05 - val_loss: 0.0179\n",
            "Epoch 253/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8746e-05 - val_loss: 0.0179\n",
            "Epoch 254/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8740e-05 - val_loss: 0.0179\n",
            "Epoch 255/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8733e-05 - val_loss: 0.0179\n",
            "Epoch 256/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8727e-05 - val_loss: 0.0180\n",
            "Epoch 257/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8721e-05 - val_loss: 0.0180\n",
            "Epoch 258/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8715e-05 - val_loss: 0.0180\n",
            "Epoch 259/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8709e-05 - val_loss: 0.0180\n",
            "Epoch 260/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8703e-05 - val_loss: 0.0180\n",
            "Epoch 261/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8697e-05 - val_loss: 0.0181\n",
            "Epoch 262/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8691e-05 - val_loss: 0.0182\n",
            "Epoch 263/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8685e-05 - val_loss: 0.0182\n",
            "Epoch 264/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8678e-05 - val_loss: 0.0183\n",
            "Epoch 265/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8672e-05 - val_loss: 0.0184\n",
            "Epoch 266/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8666e-05 - val_loss: 0.0185\n",
            "Epoch 267/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8660e-05 - val_loss: 0.0186\n",
            "Epoch 268/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8654e-05 - val_loss: 0.0187\n",
            "Epoch 269/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8648e-05 - val_loss: 0.0187\n",
            "Epoch 270/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8642e-05 - val_loss: 0.0189\n",
            "Epoch 271/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8636e-05 - val_loss: 0.0190\n",
            "Epoch 272/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8629e-05 - val_loss: 0.0191\n",
            "Epoch 273/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8623e-05 - val_loss: 0.0192\n",
            "Epoch 274/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8617e-05 - val_loss: 0.0194\n",
            "Epoch 275/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8611e-05 - val_loss: 0.0195\n",
            "Epoch 276/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8605e-05 - val_loss: 0.0196\n",
            "Epoch 277/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8599e-05 - val_loss: 0.0197\n",
            "Epoch 278/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8593e-05 - val_loss: 0.0199\n",
            "Epoch 279/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8587e-05 - val_loss: 0.0200\n",
            "Epoch 280/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8581e-05 - val_loss: 0.0201\n",
            "Epoch 281/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8575e-05 - val_loss: 0.0202\n",
            "Epoch 282/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8569e-05 - val_loss: 0.0203\n",
            "Epoch 283/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8563e-05 - val_loss: 0.0204\n",
            "Epoch 284/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8557e-05 - val_loss: 0.0205\n",
            "Epoch 285/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8552e-05 - val_loss: 0.0206\n",
            "Epoch 286/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8546e-05 - val_loss: 0.0206\n",
            "Epoch 287/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8540e-05 - val_loss: 0.0207\n",
            "Epoch 288/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8535e-05 - val_loss: 0.0208\n",
            "Epoch 289/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8529e-05 - val_loss: 0.0208\n",
            "Epoch 290/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8523e-05 - val_loss: 0.0209\n",
            "Epoch 291/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8518e-05 - val_loss: 0.0210\n",
            "Epoch 292/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8512e-05 - val_loss: 0.0211\n",
            "Epoch 293/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8507e-05 - val_loss: 0.0213\n",
            "Epoch 294/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8501e-05 - val_loss: 0.0215\n",
            "Epoch 295/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8495e-05 - val_loss: 0.0217\n",
            "Epoch 296/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8489e-05 - val_loss: 0.0219\n",
            "Epoch 297/1000\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 2.8483e-05 - val_loss: 0.0222\n",
            "Epoch 298/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8477e-05 - val_loss: 0.0224\n",
            "Epoch 299/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8471e-05 - val_loss: 0.0227\n",
            "Epoch 300/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8465e-05 - val_loss: 0.0230\n",
            "Epoch 301/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8460e-05 - val_loss: 0.0232\n",
            "Epoch 302/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8454e-05 - val_loss: 0.0234\n",
            "Epoch 303/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8448e-05 - val_loss: 0.0237\n",
            "Epoch 304/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8443e-05 - val_loss: 0.0239\n",
            "Epoch 305/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8437e-05 - val_loss: 0.0241\n",
            "Epoch 306/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8432e-05 - val_loss: 0.0242\n",
            "Epoch 307/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8426e-05 - val_loss: 0.0243\n",
            "Epoch 308/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8421e-05 - val_loss: 0.0245\n",
            "Epoch 309/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8416e-05 - val_loss: 0.0246\n",
            "Epoch 310/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8411e-05 - val_loss: 0.0247\n",
            "Epoch 311/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8405e-05 - val_loss: 0.0247\n",
            "Epoch 312/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8400e-05 - val_loss: 0.0247\n",
            "Epoch 313/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8395e-05 - val_loss: 0.0248\n",
            "Epoch 314/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8390e-05 - val_loss: 0.0249\n",
            "Epoch 315/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8385e-05 - val_loss: 0.0249\n",
            "Epoch 316/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8380e-05 - val_loss: 0.0250\n",
            "Epoch 317/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8375e-05 - val_loss: 0.0250\n",
            "Epoch 318/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8370e-05 - val_loss: 0.0250\n",
            "Epoch 319/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8365e-05 - val_loss: 0.0251\n",
            "Epoch 320/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8360e-05 - val_loss: 0.0251\n",
            "Epoch 321/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8355e-05 - val_loss: 0.0251\n",
            "Epoch 322/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8350e-05 - val_loss: 0.0251\n",
            "Epoch 323/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8345e-05 - val_loss: 0.0251\n",
            "Epoch 324/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8341e-05 - val_loss: 0.0250\n",
            "Epoch 325/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8336e-05 - val_loss: 0.0250\n",
            "Epoch 326/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8331e-05 - val_loss: 0.0250\n",
            "Epoch 327/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8326e-05 - val_loss: 0.0250\n",
            "Epoch 328/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8322e-05 - val_loss: 0.0250\n",
            "Epoch 329/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8317e-05 - val_loss: 0.0250\n",
            "Epoch 330/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8312e-05 - val_loss: 0.0250\n",
            "Epoch 331/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8308e-05 - val_loss: 0.0250\n",
            "Epoch 332/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8303e-05 - val_loss: 0.0250\n",
            "Epoch 333/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8299e-05 - val_loss: 0.0250\n",
            "Epoch 334/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8294e-05 - val_loss: 0.0250\n",
            "Epoch 335/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8289e-05 - val_loss: 0.0250\n",
            "Epoch 336/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8285e-05 - val_loss: 0.0250\n",
            "Epoch 337/1000\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.8281e-05 - val_loss: 0.0249\n",
            "Epoch 338/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8276e-05 - val_loss: 0.0249\n",
            "Epoch 339/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8272e-05 - val_loss: 0.0248\n",
            "Epoch 340/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8267e-05 - val_loss: 0.0248\n",
            "Epoch 341/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8263e-05 - val_loss: 0.0248\n",
            "Epoch 342/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8258e-05 - val_loss: 0.0248\n",
            "Epoch 343/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8254e-05 - val_loss: 0.0247\n",
            "Epoch 344/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8250e-05 - val_loss: 0.0247\n",
            "Epoch 345/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8245e-05 - val_loss: 0.0247\n",
            "Epoch 346/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8241e-05 - val_loss: 0.0247\n",
            "Epoch 347/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8237e-05 - val_loss: 0.0246\n",
            "Epoch 348/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8232e-05 - val_loss: 0.0246\n",
            "Epoch 349/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8228e-05 - val_loss: 0.0247\n",
            "Epoch 350/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8224e-05 - val_loss: 0.0247\n",
            "Epoch 351/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8219e-05 - val_loss: 0.0247\n",
            "Epoch 352/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8215e-05 - val_loss: 0.0247\n",
            "Epoch 353/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8211e-05 - val_loss: 0.0248\n",
            "Epoch 354/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8206e-05 - val_loss: 0.0250\n",
            "Epoch 355/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8202e-05 - val_loss: 0.0250\n",
            "Epoch 356/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8198e-05 - val_loss: 0.0251\n",
            "Epoch 357/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8193e-05 - val_loss: 0.0252\n",
            "Epoch 358/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8189e-05 - val_loss: 0.0252\n",
            "Epoch 359/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8185e-05 - val_loss: 0.0253\n",
            "Epoch 360/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8180e-05 - val_loss: 0.0253\n",
            "Epoch 361/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8176e-05 - val_loss: 0.0254\n",
            "Epoch 362/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8172e-05 - val_loss: 0.0254\n",
            "Epoch 363/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8168e-05 - val_loss: 0.0254\n",
            "Epoch 364/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8164e-05 - val_loss: 0.0254\n",
            "Epoch 365/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8160e-05 - val_loss: 0.0254\n",
            "Epoch 366/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8155e-05 - val_loss: 0.0254\n",
            "Epoch 367/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8151e-05 - val_loss: 0.0254\n",
            "Epoch 368/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8147e-05 - val_loss: 0.0254\n",
            "Epoch 369/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8143e-05 - val_loss: 0.0254\n",
            "Epoch 370/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8139e-05 - val_loss: 0.0254\n",
            "Epoch 371/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8135e-05 - val_loss: 0.0254\n",
            "Epoch 372/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8131e-05 - val_loss: 0.0254\n",
            "Epoch 373/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8126e-05 - val_loss: 0.0255\n",
            "Epoch 374/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8122e-05 - val_loss: 0.0255\n",
            "Epoch 375/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8118e-05 - val_loss: 0.0255\n",
            "Epoch 376/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8114e-05 - val_loss: 0.0255\n",
            "Epoch 377/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8110e-05 - val_loss: 0.0254\n",
            "Epoch 378/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8106e-05 - val_loss: 0.0255\n",
            "Epoch 379/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8102e-05 - val_loss: 0.0255\n",
            "Epoch 380/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8098e-05 - val_loss: 0.0255\n",
            "Epoch 381/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8094e-05 - val_loss: 0.0255\n",
            "Epoch 382/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8091e-05 - val_loss: 0.0255\n",
            "Epoch 383/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8087e-05 - val_loss: 0.0255\n",
            "Epoch 384/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8083e-05 - val_loss: 0.0255\n",
            "Epoch 385/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8079e-05 - val_loss: 0.0255\n",
            "Epoch 386/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8075e-05 - val_loss: 0.0255\n",
            "Epoch 387/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8072e-05 - val_loss: 0.0255\n",
            "Epoch 388/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8068e-05 - val_loss: 0.0255\n",
            "Epoch 389/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8064e-05 - val_loss: 0.0255\n",
            "Epoch 390/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8061e-05 - val_loss: 0.0255\n",
            "Epoch 391/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8057e-05 - val_loss: 0.0255\n",
            "Epoch 392/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8053e-05 - val_loss: 0.0255\n",
            "Epoch 393/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8050e-05 - val_loss: 0.0254\n",
            "Epoch 394/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8046e-05 - val_loss: 0.0254\n",
            "Epoch 395/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8042e-05 - val_loss: 0.0254\n",
            "Epoch 396/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8039e-05 - val_loss: 0.0254\n",
            "Epoch 397/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8036e-05 - val_loss: 0.0253\n",
            "Epoch 398/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8032e-05 - val_loss: 0.0253\n",
            "Epoch 399/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8028e-05 - val_loss: 0.0253\n",
            "Epoch 400/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8025e-05 - val_loss: 0.0252\n",
            "Epoch 401/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8021e-05 - val_loss: 0.0251\n",
            "Epoch 402/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8018e-05 - val_loss: 0.0251\n",
            "Epoch 403/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8015e-05 - val_loss: 0.0250\n",
            "Epoch 404/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8011e-05 - val_loss: 0.0249\n",
            "Epoch 405/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.8008e-05 - val_loss: 0.0249\n",
            "Epoch 406/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8005e-05 - val_loss: 0.0248\n",
            "Epoch 407/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.8001e-05 - val_loss: 0.0247\n",
            "Epoch 408/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7998e-05 - val_loss: 0.0247\n",
            "Epoch 409/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7995e-05 - val_loss: 0.0246\n",
            "Epoch 410/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7991e-05 - val_loss: 0.0245\n",
            "Epoch 411/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7988e-05 - val_loss: 0.0244\n",
            "Epoch 412/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7985e-05 - val_loss: 0.0244\n",
            "Epoch 413/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7982e-05 - val_loss: 0.0243\n",
            "Epoch 414/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7979e-05 - val_loss: 0.0242\n",
            "Epoch 415/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7975e-05 - val_loss: 0.0242\n",
            "Epoch 416/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7972e-05 - val_loss: 0.0241\n",
            "Epoch 417/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7969e-05 - val_loss: 0.0241\n",
            "Epoch 418/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7966e-05 - val_loss: 0.0240\n",
            "Epoch 419/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7963e-05 - val_loss: 0.0240\n",
            "Epoch 420/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7960e-05 - val_loss: 0.0239\n",
            "Epoch 421/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7957e-05 - val_loss: 0.0238\n",
            "Epoch 422/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7954e-05 - val_loss: 0.0238\n",
            "Epoch 423/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7951e-05 - val_loss: 0.0237\n",
            "Epoch 424/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7948e-05 - val_loss: 0.0236\n",
            "Epoch 425/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7945e-05 - val_loss: 0.0236\n",
            "Epoch 426/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7942e-05 - val_loss: 0.0235\n",
            "Epoch 427/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7939e-05 - val_loss: 0.0234\n",
            "Epoch 428/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7936e-05 - val_loss: 0.0234\n",
            "Epoch 429/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7933e-05 - val_loss: 0.0233\n",
            "Epoch 430/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7930e-05 - val_loss: 0.0232\n",
            "Epoch 431/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7928e-05 - val_loss: 0.0231\n",
            "Epoch 432/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7925e-05 - val_loss: 0.0230\n",
            "Epoch 433/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7922e-05 - val_loss: 0.0230\n",
            "Epoch 434/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7919e-05 - val_loss: 0.0229\n",
            "Epoch 435/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7916e-05 - val_loss: 0.0228\n",
            "Epoch 436/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7913e-05 - val_loss: 0.0227\n",
            "Epoch 437/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7911e-05 - val_loss: 0.0227\n",
            "Epoch 438/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7908e-05 - val_loss: 0.0226\n",
            "Epoch 439/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7905e-05 - val_loss: 0.0225\n",
            "Epoch 440/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7903e-05 - val_loss: 0.0225\n",
            "Epoch 441/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7900e-05 - val_loss: 0.0224\n",
            "Epoch 442/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7897e-05 - val_loss: 0.0224\n",
            "Epoch 443/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7895e-05 - val_loss: 0.0223\n",
            "Epoch 444/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7892e-05 - val_loss: 0.0223\n",
            "Epoch 445/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7890e-05 - val_loss: 0.0222\n",
            "Epoch 446/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7887e-05 - val_loss: 0.0222\n",
            "Epoch 447/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7884e-05 - val_loss: 0.0221\n",
            "Epoch 448/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7882e-05 - val_loss: 0.0220\n",
            "Epoch 449/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7879e-05 - val_loss: 0.0220\n",
            "Epoch 450/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7877e-05 - val_loss: 0.0219\n",
            "Epoch 451/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7874e-05 - val_loss: 0.0218\n",
            "Epoch 452/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7872e-05 - val_loss: 0.0218\n",
            "Epoch 453/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7869e-05 - val_loss: 0.0217\n",
            "Epoch 454/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7867e-05 - val_loss: 0.0216\n",
            "Epoch 455/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7864e-05 - val_loss: 0.0215\n",
            "Epoch 456/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7862e-05 - val_loss: 0.0215\n",
            "Epoch 457/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7859e-05 - val_loss: 0.0214\n",
            "Epoch 458/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7857e-05 - val_loss: 0.0213\n",
            "Epoch 459/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7855e-05 - val_loss: 0.0212\n",
            "Epoch 460/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7852e-05 - val_loss: 0.0212\n",
            "Epoch 461/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7850e-05 - val_loss: 0.0211\n",
            "Epoch 462/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7847e-05 - val_loss: 0.0210\n",
            "Epoch 463/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7845e-05 - val_loss: 0.0209\n",
            "Epoch 464/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7843e-05 - val_loss: 0.0208\n",
            "Epoch 465/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7841e-05 - val_loss: 0.0208\n",
            "Epoch 466/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7838e-05 - val_loss: 0.0207\n",
            "Epoch 467/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7836e-05 - val_loss: 0.0206\n",
            "Epoch 468/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7834e-05 - val_loss: 0.0205\n",
            "Epoch 469/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7832e-05 - val_loss: 0.0204\n",
            "Epoch 470/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7829e-05 - val_loss: 0.0204\n",
            "Epoch 471/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7827e-05 - val_loss: 0.0203\n",
            "Epoch 472/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7825e-05 - val_loss: 0.0202\n",
            "Epoch 473/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7823e-05 - val_loss: 0.0201\n",
            "Epoch 474/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7821e-05 - val_loss: 0.0200\n",
            "Epoch 475/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7819e-05 - val_loss: 0.0200\n",
            "Epoch 476/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7817e-05 - val_loss: 0.0199\n",
            "Epoch 477/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7814e-05 - val_loss: 0.0198\n",
            "Epoch 478/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7812e-05 - val_loss: 0.0197\n",
            "Epoch 479/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7810e-05 - val_loss: 0.0196\n",
            "Epoch 480/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7808e-05 - val_loss: 0.0196\n",
            "Epoch 481/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7806e-05 - val_loss: 0.0195\n",
            "Epoch 482/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7804e-05 - val_loss: 0.0194\n",
            "Epoch 483/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7802e-05 - val_loss: 0.0193\n",
            "Epoch 484/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7800e-05 - val_loss: 0.0193\n",
            "Epoch 485/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7798e-05 - val_loss: 0.0192\n",
            "Epoch 486/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7796e-05 - val_loss: 0.0192\n",
            "Epoch 487/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7794e-05 - val_loss: 0.0191\n",
            "Epoch 488/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7792e-05 - val_loss: 0.0190\n",
            "Epoch 489/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7790e-05 - val_loss: 0.0189\n",
            "Epoch 490/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7788e-05 - val_loss: 0.0189\n",
            "Epoch 491/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7786e-05 - val_loss: 0.0188\n",
            "Epoch 492/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7785e-05 - val_loss: 0.0187\n",
            "Epoch 493/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7782e-05 - val_loss: 0.0187\n",
            "Epoch 494/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7781e-05 - val_loss: 0.0186\n",
            "Epoch 495/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7779e-05 - val_loss: 0.0185\n",
            "Epoch 496/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7777e-05 - val_loss: 0.0185\n",
            "Epoch 497/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7776e-05 - val_loss: 0.0184\n",
            "Epoch 498/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7773e-05 - val_loss: 0.0183\n",
            "Epoch 499/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7772e-05 - val_loss: 0.0183\n",
            "Epoch 500/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7770e-05 - val_loss: 0.0182\n",
            "Epoch 501/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7768e-05 - val_loss: 0.0181\n",
            "Epoch 502/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7766e-05 - val_loss: 0.0181\n",
            "Epoch 503/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7764e-05 - val_loss: 0.0180\n",
            "Epoch 504/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7763e-05 - val_loss: 0.0179\n",
            "Epoch 505/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7761e-05 - val_loss: 0.0178\n",
            "Epoch 506/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7759e-05 - val_loss: 0.0178\n",
            "Epoch 507/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7758e-05 - val_loss: 0.0177\n",
            "Epoch 508/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7756e-05 - val_loss: 0.0176\n",
            "Epoch 509/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7754e-05 - val_loss: 0.0176\n",
            "Epoch 510/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7753e-05 - val_loss: 0.0175\n",
            "Epoch 511/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7751e-05 - val_loss: 0.0174\n",
            "Epoch 512/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7749e-05 - val_loss: 0.0174\n",
            "Epoch 513/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7748e-05 - val_loss: 0.0173\n",
            "Epoch 514/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7746e-05 - val_loss: 0.0172\n",
            "Epoch 515/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7744e-05 - val_loss: 0.0171\n",
            "Epoch 516/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7743e-05 - val_loss: 0.0171\n",
            "Epoch 517/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7741e-05 - val_loss: 0.0170\n",
            "Epoch 518/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7739e-05 - val_loss: 0.0169\n",
            "Epoch 519/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7738e-05 - val_loss: 0.0168\n",
            "Epoch 520/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7736e-05 - val_loss: 0.0167\n",
            "Epoch 521/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7735e-05 - val_loss: 0.0167\n",
            "Epoch 522/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7733e-05 - val_loss: 0.0166\n",
            "Epoch 523/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7732e-05 - val_loss: 0.0165\n",
            "Epoch 524/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7730e-05 - val_loss: 0.0165\n",
            "Epoch 525/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7728e-05 - val_loss: 0.0164\n",
            "Epoch 526/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7727e-05 - val_loss: 0.0163\n",
            "Epoch 527/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7726e-05 - val_loss: 0.0162\n",
            "Epoch 528/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7724e-05 - val_loss: 0.0162\n",
            "Epoch 529/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7722e-05 - val_loss: 0.0161\n",
            "Epoch 530/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7721e-05 - val_loss: 0.0160\n",
            "Epoch 531/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7719e-05 - val_loss: 0.0160\n",
            "Epoch 532/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7718e-05 - val_loss: 0.0159\n",
            "Epoch 533/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7717e-05 - val_loss: 0.0158\n",
            "Epoch 534/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7715e-05 - val_loss: 0.0157\n",
            "Epoch 535/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7714e-05 - val_loss: 0.0157\n",
            "Epoch 536/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7712e-05 - val_loss: 0.0156\n",
            "Epoch 537/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7711e-05 - val_loss: 0.0155\n",
            "Epoch 538/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7710e-05 - val_loss: 0.0154\n",
            "Epoch 539/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7709e-05 - val_loss: 0.0153\n",
            "Epoch 540/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7707e-05 - val_loss: 0.0152\n",
            "Epoch 541/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7706e-05 - val_loss: 0.0152\n",
            "Epoch 542/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7705e-05 - val_loss: 0.0151\n",
            "Epoch 543/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7703e-05 - val_loss: 0.0150\n",
            "Epoch 544/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7702e-05 - val_loss: 0.0149\n",
            "Epoch 545/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7700e-05 - val_loss: 0.0148\n",
            "Epoch 546/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7699e-05 - val_loss: 0.0148\n",
            "Epoch 547/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7697e-05 - val_loss: 0.0147\n",
            "Epoch 548/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7696e-05 - val_loss: 0.0146\n",
            "Epoch 549/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7695e-05 - val_loss: 0.0145\n",
            "Epoch 550/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7693e-05 - val_loss: 0.0145\n",
            "Epoch 551/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7692e-05 - val_loss: 0.0144\n",
            "Epoch 552/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7690e-05 - val_loss: 0.0143\n",
            "Epoch 553/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7689e-05 - val_loss: 0.0143\n",
            "Epoch 554/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7688e-05 - val_loss: 0.0142\n",
            "Epoch 555/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7687e-05 - val_loss: 0.0141\n",
            "Epoch 556/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7685e-05 - val_loss: 0.0141\n",
            "Epoch 557/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7684e-05 - val_loss: 0.0140\n",
            "Epoch 558/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7683e-05 - val_loss: 0.0140\n",
            "Epoch 559/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7681e-05 - val_loss: 0.0139\n",
            "Epoch 560/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7680e-05 - val_loss: 0.0138\n",
            "Epoch 561/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7679e-05 - val_loss: 0.0138\n",
            "Epoch 562/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7677e-05 - val_loss: 0.0137\n",
            "Epoch 563/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7676e-05 - val_loss: 0.0136\n",
            "Epoch 564/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7675e-05 - val_loss: 0.0136\n",
            "Epoch 565/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7674e-05 - val_loss: 0.0135\n",
            "Epoch 566/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7673e-05 - val_loss: 0.0134\n",
            "Epoch 567/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7671e-05 - val_loss: 0.0134\n",
            "Epoch 568/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7670e-05 - val_loss: 0.0133\n",
            "Epoch 569/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7669e-05 - val_loss: 0.0132\n",
            "Epoch 570/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7668e-05 - val_loss: 0.0132\n",
            "Epoch 571/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7667e-05 - val_loss: 0.0131\n",
            "Epoch 572/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7666e-05 - val_loss: 0.0130\n",
            "Epoch 573/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7664e-05 - val_loss: 0.0130\n",
            "Epoch 574/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7663e-05 - val_loss: 0.0129\n",
            "Epoch 575/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7662e-05 - val_loss: 0.0128\n",
            "Epoch 576/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7661e-05 - val_loss: 0.0128\n",
            "Epoch 577/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7659e-05 - val_loss: 0.0127\n",
            "Epoch 578/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7658e-05 - val_loss: 0.0126\n",
            "Epoch 579/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7657e-05 - val_loss: 0.0126\n",
            "Epoch 580/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7656e-05 - val_loss: 0.0125\n",
            "Epoch 581/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7655e-05 - val_loss: 0.0124\n",
            "Epoch 582/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7653e-05 - val_loss: 0.0124\n",
            "Epoch 583/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7652e-05 - val_loss: 0.0123\n",
            "Epoch 584/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7651e-05 - val_loss: 0.0122\n",
            "Epoch 585/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7650e-05 - val_loss: 0.0122\n",
            "Epoch 586/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7649e-05 - val_loss: 0.0121\n",
            "Epoch 587/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7648e-05 - val_loss: 0.0121\n",
            "Epoch 588/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7646e-05 - val_loss: 0.0120\n",
            "Epoch 589/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7645e-05 - val_loss: 0.0120\n",
            "Epoch 590/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7644e-05 - val_loss: 0.0119\n",
            "Epoch 591/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7643e-05 - val_loss: 0.0119\n",
            "Epoch 592/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7642e-05 - val_loss: 0.0118\n",
            "Epoch 593/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7641e-05 - val_loss: 0.0118\n",
            "Epoch 594/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7639e-05 - val_loss: 0.0117\n",
            "Epoch 595/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7638e-05 - val_loss: 0.0117\n",
            "Epoch 596/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7637e-05 - val_loss: 0.0116\n",
            "Epoch 597/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7636e-05 - val_loss: 0.0115\n",
            "Epoch 598/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7635e-05 - val_loss: 0.0115\n",
            "Epoch 599/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7634e-05 - val_loss: 0.0114\n",
            "Epoch 600/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7633e-05 - val_loss: 0.0114\n",
            "Epoch 601/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7632e-05 - val_loss: 0.0113\n",
            "Epoch 602/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7631e-05 - val_loss: 0.0113\n",
            "Epoch 603/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7630e-05 - val_loss: 0.0113\n",
            "Epoch 604/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7628e-05 - val_loss: 0.0112\n",
            "Epoch 605/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7627e-05 - val_loss: 0.0112\n",
            "Epoch 606/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7626e-05 - val_loss: 0.0111\n",
            "Epoch 607/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7625e-05 - val_loss: 0.0111\n",
            "Epoch 608/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7624e-05 - val_loss: 0.0110\n",
            "Epoch 609/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7623e-05 - val_loss: 0.0110\n",
            "Epoch 610/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7622e-05 - val_loss: 0.0109\n",
            "Epoch 611/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7621e-05 - val_loss: 0.0109\n",
            "Epoch 612/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7620e-05 - val_loss: 0.0108\n",
            "Epoch 613/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7619e-05 - val_loss: 0.0108\n",
            "Epoch 614/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7617e-05 - val_loss: 0.0107\n",
            "Epoch 615/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7617e-05 - val_loss: 0.0107\n",
            "Epoch 616/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7615e-05 - val_loss: 0.0106\n",
            "Epoch 617/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7614e-05 - val_loss: 0.0106\n",
            "Epoch 618/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7613e-05 - val_loss: 0.0105\n",
            "Epoch 619/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7612e-05 - val_loss: 0.0105\n",
            "Epoch 620/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7611e-05 - val_loss: 0.0104\n",
            "Epoch 621/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7610e-05 - val_loss: 0.0104\n",
            "Epoch 622/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7609e-05 - val_loss: 0.0103\n",
            "Epoch 623/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7608e-05 - val_loss: 0.0103\n",
            "Epoch 624/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7607e-05 - val_loss: 0.0102\n",
            "Epoch 625/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7606e-05 - val_loss: 0.0102\n",
            "Epoch 626/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7605e-05 - val_loss: 0.0102\n",
            "Epoch 627/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7604e-05 - val_loss: 0.0101\n",
            "Epoch 628/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7603e-05 - val_loss: 0.0101\n",
            "Epoch 629/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7602e-05 - val_loss: 0.0100\n",
            "Epoch 630/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7601e-05 - val_loss: 0.0100\n",
            "Epoch 631/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7600e-05 - val_loss: 0.0099\n",
            "Epoch 632/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7599e-05 - val_loss: 0.0099\n",
            "Epoch 633/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7598e-05 - val_loss: 0.0098\n",
            "Epoch 634/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7597e-05 - val_loss: 0.0098\n",
            "Epoch 635/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7596e-05 - val_loss: 0.0097\n",
            "Epoch 636/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7595e-05 - val_loss: 0.0097\n",
            "Epoch 637/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7594e-05 - val_loss: 0.0096\n",
            "Epoch 638/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7593e-05 - val_loss: 0.0096\n",
            "Epoch 639/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7592e-05 - val_loss: 0.0096\n",
            "Epoch 640/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7591e-05 - val_loss: 0.0095\n",
            "Epoch 641/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7590e-05 - val_loss: 0.0095\n",
            "Epoch 642/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7589e-05 - val_loss: 0.0094\n",
            "Epoch 643/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7588e-05 - val_loss: 0.0094\n",
            "Epoch 644/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7587e-05 - val_loss: 0.0093\n",
            "Epoch 645/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7586e-05 - val_loss: 0.0093\n",
            "Epoch 646/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7585e-05 - val_loss: 0.0093\n",
            "Epoch 647/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7584e-05 - val_loss: 0.0092\n",
            "Epoch 648/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7583e-05 - val_loss: 0.0092\n",
            "Epoch 649/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7582e-05 - val_loss: 0.0091\n",
            "Epoch 650/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7581e-05 - val_loss: 0.0091\n",
            "Epoch 651/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7580e-05 - val_loss: 0.0090\n",
            "Epoch 652/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7579e-05 - val_loss: 0.0090\n",
            "Epoch 653/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7578e-05 - val_loss: 0.0090\n",
            "Epoch 654/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7578e-05 - val_loss: 0.0089\n",
            "Epoch 655/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7577e-05 - val_loss: 0.0089\n",
            "Epoch 656/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7576e-05 - val_loss: 0.0088\n",
            "Epoch 657/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7575e-05 - val_loss: 0.0088\n",
            "Epoch 658/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7574e-05 - val_loss: 0.0087\n",
            "Epoch 659/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7573e-05 - val_loss: 0.0087\n",
            "Epoch 660/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7572e-05 - val_loss: 0.0087\n",
            "Epoch 661/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7571e-05 - val_loss: 0.0086\n",
            "Epoch 662/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7570e-05 - val_loss: 0.0086\n",
            "Epoch 663/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7569e-05 - val_loss: 0.0085\n",
            "Epoch 664/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7568e-05 - val_loss: 0.0085\n",
            "Epoch 665/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7568e-05 - val_loss: 0.0085\n",
            "Epoch 666/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7566e-05 - val_loss: 0.0084\n",
            "Epoch 667/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7566e-05 - val_loss: 0.0084\n",
            "Epoch 668/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7565e-05 - val_loss: 0.0083\n",
            "Epoch 669/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7564e-05 - val_loss: 0.0083\n",
            "Epoch 670/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7563e-05 - val_loss: 0.0083\n",
            "Epoch 671/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7562e-05 - val_loss: 0.0082\n",
            "Epoch 672/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7561e-05 - val_loss: 0.0082\n",
            "Epoch 673/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7560e-05 - val_loss: 0.0081\n",
            "Epoch 674/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7559e-05 - val_loss: 0.0081\n",
            "Epoch 675/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7558e-05 - val_loss: 0.0081\n",
            "Epoch 676/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7557e-05 - val_loss: 0.0080\n",
            "Epoch 677/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7557e-05 - val_loss: 0.0080\n",
            "Epoch 678/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7556e-05 - val_loss: 0.0079\n",
            "Epoch 679/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7555e-05 - val_loss: 0.0079\n",
            "Epoch 680/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7554e-05 - val_loss: 0.0079\n",
            "Epoch 681/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7553e-05 - val_loss: 0.0078\n",
            "Epoch 682/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7552e-05 - val_loss: 0.0078\n",
            "Epoch 683/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7551e-05 - val_loss: 0.0078\n",
            "Epoch 684/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7550e-05 - val_loss: 0.0077\n",
            "Epoch 685/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7549e-05 - val_loss: 0.0077\n",
            "Epoch 686/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7549e-05 - val_loss: 0.0077\n",
            "Epoch 687/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7548e-05 - val_loss: 0.0076\n",
            "Epoch 688/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7547e-05 - val_loss: 0.0076\n",
            "Epoch 689/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7546e-05 - val_loss: 0.0076\n",
            "Epoch 690/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7545e-05 - val_loss: 0.0075\n",
            "Epoch 691/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7544e-05 - val_loss: 0.0075\n",
            "Epoch 692/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7543e-05 - val_loss: 0.0075\n",
            "Epoch 693/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7542e-05 - val_loss: 0.0074\n",
            "Epoch 694/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7541e-05 - val_loss: 0.0074\n",
            "Epoch 695/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7541e-05 - val_loss: 0.0074\n",
            "Epoch 696/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7540e-05 - val_loss: 0.0073\n",
            "Epoch 697/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7539e-05 - val_loss: 0.0073\n",
            "Epoch 698/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7538e-05 - val_loss: 0.0073\n",
            "Epoch 699/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7537e-05 - val_loss: 0.0072\n",
            "Epoch 700/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7536e-05 - val_loss: 0.0072\n",
            "Epoch 701/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7535e-05 - val_loss: 0.0072\n",
            "Epoch 702/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7534e-05 - val_loss: 0.0072\n",
            "Epoch 703/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7534e-05 - val_loss: 0.0071\n",
            "Epoch 704/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7533e-05 - val_loss: 0.0071\n",
            "Epoch 705/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7532e-05 - val_loss: 0.0071\n",
            "Epoch 706/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7531e-05 - val_loss: 0.0071\n",
            "Epoch 707/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7530e-05 - val_loss: 0.0070\n",
            "Epoch 708/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7529e-05 - val_loss: 0.0070\n",
            "Epoch 709/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7528e-05 - val_loss: 0.0070\n",
            "Epoch 710/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7528e-05 - val_loss: 0.0070\n",
            "Epoch 711/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7527e-05 - val_loss: 0.0069\n",
            "Epoch 712/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7526e-05 - val_loss: 0.0069\n",
            "Epoch 713/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7525e-05 - val_loss: 0.0069\n",
            "Epoch 714/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7524e-05 - val_loss: 0.0068\n",
            "Epoch 715/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7523e-05 - val_loss: 0.0068\n",
            "Epoch 716/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7523e-05 - val_loss: 0.0068\n",
            "Epoch 717/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7522e-05 - val_loss: 0.0068\n",
            "Epoch 718/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7521e-05 - val_loss: 0.0067\n",
            "Epoch 719/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7520e-05 - val_loss: 0.0067\n",
            "Epoch 720/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7519e-05 - val_loss: 0.0067\n",
            "Epoch 721/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7519e-05 - val_loss: 0.0067\n",
            "Epoch 722/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7518e-05 - val_loss: 0.0066\n",
            "Epoch 723/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7517e-05 - val_loss: 0.0066\n",
            "Epoch 724/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7516e-05 - val_loss: 0.0066\n",
            "Epoch 725/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7515e-05 - val_loss: 0.0066\n",
            "Epoch 726/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7514e-05 - val_loss: 0.0065\n",
            "Epoch 727/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7514e-05 - val_loss: 0.0065\n",
            "Epoch 728/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7513e-05 - val_loss: 0.0065\n",
            "Epoch 729/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7512e-05 - val_loss: 0.0064\n",
            "Epoch 730/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7511e-05 - val_loss: 0.0064\n",
            "Epoch 731/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7510e-05 - val_loss: 0.0064\n",
            "Epoch 732/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7510e-05 - val_loss: 0.0064\n",
            "Epoch 733/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7509e-05 - val_loss: 0.0063\n",
            "Epoch 734/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7508e-05 - val_loss: 0.0063\n",
            "Epoch 735/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7507e-05 - val_loss: 0.0063\n",
            "Epoch 736/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7507e-05 - val_loss: 0.0063\n",
            "Epoch 737/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7506e-05 - val_loss: 0.0063\n",
            "Epoch 738/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7505e-05 - val_loss: 0.0062\n",
            "Epoch 739/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7504e-05 - val_loss: 0.0062\n",
            "Epoch 740/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7503e-05 - val_loss: 0.0062\n",
            "Epoch 741/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7503e-05 - val_loss: 0.0062\n",
            "Epoch 742/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7502e-05 - val_loss: 0.0061\n",
            "Epoch 743/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7501e-05 - val_loss: 0.0061\n",
            "Epoch 744/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7500e-05 - val_loss: 0.0061\n",
            "Epoch 745/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7500e-05 - val_loss: 0.0061\n",
            "Epoch 746/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7499e-05 - val_loss: 0.0060\n",
            "Epoch 747/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7498e-05 - val_loss: 0.0060\n",
            "Epoch 748/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7497e-05 - val_loss: 0.0060\n",
            "Epoch 749/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7496e-05 - val_loss: 0.0060\n",
            "Epoch 750/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7496e-05 - val_loss: 0.0059\n",
            "Epoch 751/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7495e-05 - val_loss: 0.0059\n",
            "Epoch 752/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7494e-05 - val_loss: 0.0059\n",
            "Epoch 753/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7493e-05 - val_loss: 0.0059\n",
            "Epoch 754/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7492e-05 - val_loss: 0.0058\n",
            "Epoch 755/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7492e-05 - val_loss: 0.0058\n",
            "Epoch 756/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7491e-05 - val_loss: 0.0058\n",
            "Epoch 757/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7490e-05 - val_loss: 0.0058\n",
            "Epoch 758/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7489e-05 - val_loss: 0.0058\n",
            "Epoch 759/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7489e-05 - val_loss: 0.0057\n",
            "Epoch 760/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7488e-05 - val_loss: 0.0057\n",
            "Epoch 761/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7487e-05 - val_loss: 0.0057\n",
            "Epoch 762/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7487e-05 - val_loss: 0.0057\n",
            "Epoch 763/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7486e-05 - val_loss: 0.0056\n",
            "Epoch 764/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7485e-05 - val_loss: 0.0056\n",
            "Epoch 765/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7484e-05 - val_loss: 0.0056\n",
            "Epoch 766/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7483e-05 - val_loss: 0.0056\n",
            "Epoch 767/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7483e-05 - val_loss: 0.0056\n",
            "Epoch 768/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7482e-05 - val_loss: 0.0055\n",
            "Epoch 769/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7481e-05 - val_loss: 0.0055\n",
            "Epoch 770/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7480e-05 - val_loss: 0.0055\n",
            "Epoch 771/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7480e-05 - val_loss: 0.0055\n",
            "Epoch 772/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7479e-05 - val_loss: 0.0054\n",
            "Epoch 773/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7478e-05 - val_loss: 0.0054\n",
            "Epoch 774/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7478e-05 - val_loss: 0.0054\n",
            "Epoch 775/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7477e-05 - val_loss: 0.0054\n",
            "Epoch 776/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7476e-05 - val_loss: 0.0054\n",
            "Epoch 777/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7475e-05 - val_loss: 0.0053\n",
            "Epoch 778/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7475e-05 - val_loss: 0.0053\n",
            "Epoch 779/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7474e-05 - val_loss: 0.0053\n",
            "Epoch 780/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7474e-05 - val_loss: 0.0053\n",
            "Epoch 781/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7473e-05 - val_loss: 0.0053\n",
            "Epoch 782/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7472e-05 - val_loss: 0.0053\n",
            "Epoch 783/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7471e-05 - val_loss: 0.0053\n",
            "Epoch 784/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7470e-05 - val_loss: 0.0052\n",
            "Epoch 785/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7470e-05 - val_loss: 0.0052\n",
            "Epoch 786/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7469e-05 - val_loss: 0.0052\n",
            "Epoch 787/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7468e-05 - val_loss: 0.0052\n",
            "Epoch 788/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7467e-05 - val_loss: 0.0052\n",
            "Epoch 789/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7467e-05 - val_loss: 0.0052\n",
            "Epoch 790/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7466e-05 - val_loss: 0.0051\n",
            "Epoch 791/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7465e-05 - val_loss: 0.0051\n",
            "Epoch 792/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7465e-05 - val_loss: 0.0051\n",
            "Epoch 793/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7464e-05 - val_loss: 0.0051\n",
            "Epoch 794/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7463e-05 - val_loss: 0.0051\n",
            "Epoch 795/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7462e-05 - val_loss: 0.0051\n",
            "Epoch 796/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7462e-05 - val_loss: 0.0050\n",
            "Epoch 797/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7461e-05 - val_loss: 0.0050\n",
            "Epoch 798/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7460e-05 - val_loss: 0.0050\n",
            "Epoch 799/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7460e-05 - val_loss: 0.0050\n",
            "Epoch 800/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7459e-05 - val_loss: 0.0050\n",
            "Epoch 801/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7458e-05 - val_loss: 0.0050\n",
            "Epoch 802/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7457e-05 - val_loss: 0.0050\n",
            "Epoch 803/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7457e-05 - val_loss: 0.0049\n",
            "Epoch 804/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7456e-05 - val_loss: 0.0049\n",
            "Epoch 805/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7455e-05 - val_loss: 0.0049\n",
            "Epoch 806/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7455e-05 - val_loss: 0.0049\n",
            "Epoch 807/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7454e-05 - val_loss: 0.0049\n",
            "Epoch 808/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7453e-05 - val_loss: 0.0049\n",
            "Epoch 809/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7453e-05 - val_loss: 0.0049\n",
            "Epoch 810/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7452e-05 - val_loss: 0.0048\n",
            "Epoch 811/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7451e-05 - val_loss: 0.0048\n",
            "Epoch 812/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7450e-05 - val_loss: 0.0048\n",
            "Epoch 813/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7450e-05 - val_loss: 0.0048\n",
            "Epoch 814/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7449e-05 - val_loss: 0.0048\n",
            "Epoch 815/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7448e-05 - val_loss: 0.0048\n",
            "Epoch 816/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7448e-05 - val_loss: 0.0048\n",
            "Epoch 817/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7447e-05 - val_loss: 0.0047\n",
            "Epoch 818/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7446e-05 - val_loss: 0.0047\n",
            "Epoch 819/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7445e-05 - val_loss: 0.0047\n",
            "Epoch 820/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7445e-05 - val_loss: 0.0047\n",
            "Epoch 821/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7444e-05 - val_loss: 0.0047\n",
            "Epoch 822/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7443e-05 - val_loss: 0.0047\n",
            "Epoch 823/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7443e-05 - val_loss: 0.0046\n",
            "Epoch 824/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7442e-05 - val_loss: 0.0046\n",
            "Epoch 825/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7441e-05 - val_loss: 0.0046\n",
            "Epoch 826/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7441e-05 - val_loss: 0.0046\n",
            "Epoch 827/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7440e-05 - val_loss: 0.0046\n",
            "Epoch 828/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7439e-05 - val_loss: 0.0046\n",
            "Epoch 829/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7438e-05 - val_loss: 0.0046\n",
            "Epoch 830/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7438e-05 - val_loss: 0.0045\n",
            "Epoch 831/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7437e-05 - val_loss: 0.0045\n",
            "Epoch 832/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7436e-05 - val_loss: 0.0045\n",
            "Epoch 833/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7436e-05 - val_loss: 0.0045\n",
            "Epoch 834/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7435e-05 - val_loss: 0.0045\n",
            "Epoch 835/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7434e-05 - val_loss: 0.0045\n",
            "Epoch 836/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7434e-05 - val_loss: 0.0045\n",
            "Epoch 837/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7433e-05 - val_loss: 0.0044\n",
            "Epoch 838/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7432e-05 - val_loss: 0.0044\n",
            "Epoch 839/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7432e-05 - val_loss: 0.0044\n",
            "Epoch 840/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7431e-05 - val_loss: 0.0044\n",
            "Epoch 841/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7430e-05 - val_loss: 0.0044\n",
            "Epoch 842/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7430e-05 - val_loss: 0.0044\n",
            "Epoch 843/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7429e-05 - val_loss: 0.0044\n",
            "Epoch 844/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7428e-05 - val_loss: 0.0043\n",
            "Epoch 845/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7428e-05 - val_loss: 0.0043\n",
            "Epoch 846/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7427e-05 - val_loss: 0.0043\n",
            "Epoch 847/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7426e-05 - val_loss: 0.0043\n",
            "Epoch 848/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7426e-05 - val_loss: 0.0043\n",
            "Epoch 849/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7425e-05 - val_loss: 0.0043\n",
            "Epoch 850/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7424e-05 - val_loss: 0.0043\n",
            "Epoch 851/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7424e-05 - val_loss: 0.0043\n",
            "Epoch 852/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7423e-05 - val_loss: 0.0042\n",
            "Epoch 853/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7422e-05 - val_loss: 0.0042\n",
            "Epoch 854/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7422e-05 - val_loss: 0.0042\n",
            "Epoch 855/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7421e-05 - val_loss: 0.0042\n",
            "Epoch 856/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7421e-05 - val_loss: 0.0042\n",
            "Epoch 857/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7420e-05 - val_loss: 0.0042\n",
            "Epoch 858/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7419e-05 - val_loss: 0.0042\n",
            "Epoch 859/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7419e-05 - val_loss: 0.0042\n",
            "Epoch 860/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7418e-05 - val_loss: 0.0042\n",
            "Epoch 861/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7417e-05 - val_loss: 0.0042\n",
            "Epoch 862/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7417e-05 - val_loss: 0.0041\n",
            "Epoch 863/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7416e-05 - val_loss: 0.0041\n",
            "Epoch 864/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7415e-05 - val_loss: 0.0041\n",
            "Epoch 865/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7415e-05 - val_loss: 0.0041\n",
            "Epoch 866/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7414e-05 - val_loss: 0.0041\n",
            "Epoch 867/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7414e-05 - val_loss: 0.0041\n",
            "Epoch 868/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7413e-05 - val_loss: 0.0041\n",
            "Epoch 869/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7412e-05 - val_loss: 0.0041\n",
            "Epoch 870/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7412e-05 - val_loss: 0.0041\n",
            "Epoch 871/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7411e-05 - val_loss: 0.0040\n",
            "Epoch 872/1000\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.7410e-05 - val_loss: 0.0040\n",
            "Epoch 873/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7410e-05 - val_loss: 0.0040\n",
            "Epoch 874/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7409e-05 - val_loss: 0.0040\n",
            "Epoch 875/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7409e-05 - val_loss: 0.0040\n",
            "Epoch 876/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7408e-05 - val_loss: 0.0040\n",
            "Epoch 877/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7408e-05 - val_loss: 0.0040\n",
            "Epoch 878/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7407e-05 - val_loss: 0.0040\n",
            "Epoch 879/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7406e-05 - val_loss: 0.0040\n",
            "Epoch 880/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7405e-05 - val_loss: 0.0040\n",
            "Epoch 881/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7405e-05 - val_loss: 0.0039\n",
            "Epoch 882/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7404e-05 - val_loss: 0.0039\n",
            "Epoch 883/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7404e-05 - val_loss: 0.0039\n",
            "Epoch 884/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7403e-05 - val_loss: 0.0039\n",
            "Epoch 885/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7402e-05 - val_loss: 0.0039\n",
            "Epoch 886/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7402e-05 - val_loss: 0.0039\n",
            "Epoch 887/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7401e-05 - val_loss: 0.0039\n",
            "Epoch 888/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7401e-05 - val_loss: 0.0039\n",
            "Epoch 889/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7400e-05 - val_loss: 0.0039\n",
            "Epoch 890/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7399e-05 - val_loss: 0.0039\n",
            "Epoch 891/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7399e-05 - val_loss: 0.0038\n",
            "Epoch 892/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7398e-05 - val_loss: 0.0038\n",
            "Epoch 893/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7398e-05 - val_loss: 0.0038\n",
            "Epoch 894/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7397e-05 - val_loss: 0.0038\n",
            "Epoch 895/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7396e-05 - val_loss: 0.0038\n",
            "Epoch 896/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7396e-05 - val_loss: 0.0038\n",
            "Epoch 897/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7395e-05 - val_loss: 0.0038\n",
            "Epoch 898/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7394e-05 - val_loss: 0.0038\n",
            "Epoch 899/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7394e-05 - val_loss: 0.0038\n",
            "Epoch 900/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7393e-05 - val_loss: 0.0038\n",
            "Epoch 901/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7393e-05 - val_loss: 0.0038\n",
            "Epoch 902/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7392e-05 - val_loss: 0.0037\n",
            "Epoch 903/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7392e-05 - val_loss: 0.0037\n",
            "Epoch 904/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7391e-05 - val_loss: 0.0037\n",
            "Epoch 905/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7390e-05 - val_loss: 0.0037\n",
            "Epoch 906/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7390e-05 - val_loss: 0.0037\n",
            "Epoch 907/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7389e-05 - val_loss: 0.0037\n",
            "Epoch 908/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7389e-05 - val_loss: 0.0037\n",
            "Epoch 909/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7388e-05 - val_loss: 0.0037\n",
            "Epoch 910/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7387e-05 - val_loss: 0.0037\n",
            "Epoch 911/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7387e-05 - val_loss: 0.0037\n",
            "Epoch 912/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7386e-05 - val_loss: 0.0037\n",
            "Epoch 913/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7386e-05 - val_loss: 0.0037\n",
            "Epoch 914/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7385e-05 - val_loss: 0.0037\n",
            "Epoch 915/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7385e-05 - val_loss: 0.0036\n",
            "Epoch 916/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7384e-05 - val_loss: 0.0036\n",
            "Epoch 917/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7383e-05 - val_loss: 0.0036\n",
            "Epoch 918/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7383e-05 - val_loss: 0.0036\n",
            "Epoch 919/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7382e-05 - val_loss: 0.0036\n",
            "Epoch 920/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7381e-05 - val_loss: 0.0036\n",
            "Epoch 921/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7381e-05 - val_loss: 0.0036\n",
            "Epoch 922/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7380e-05 - val_loss: 0.0036\n",
            "Epoch 923/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7380e-05 - val_loss: 0.0036\n",
            "Epoch 924/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7379e-05 - val_loss: 0.0036\n",
            "Epoch 925/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7379e-05 - val_loss: 0.0036\n",
            "Epoch 926/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7378e-05 - val_loss: 0.0036\n",
            "Epoch 927/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7378e-05 - val_loss: 0.0036\n",
            "Epoch 928/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7377e-05 - val_loss: 0.0036\n",
            "Epoch 929/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7376e-05 - val_loss: 0.0035\n",
            "Epoch 930/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7376e-05 - val_loss: 0.0035\n",
            "Epoch 931/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7375e-05 - val_loss: 0.0035\n",
            "Epoch 932/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7375e-05 - val_loss: 0.0035\n",
            "Epoch 933/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7374e-05 - val_loss: 0.0035\n",
            "Epoch 934/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7374e-05 - val_loss: 0.0035\n",
            "Epoch 935/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7373e-05 - val_loss: 0.0035\n",
            "Epoch 936/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7373e-05 - val_loss: 0.0035\n",
            "Epoch 937/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7372e-05 - val_loss: 0.0035\n",
            "Epoch 938/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7372e-05 - val_loss: 0.0035\n",
            "Epoch 939/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7371e-05 - val_loss: 0.0035\n",
            "Epoch 940/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7370e-05 - val_loss: 0.0035\n",
            "Epoch 941/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7370e-05 - val_loss: 0.0035\n",
            "Epoch 942/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7369e-05 - val_loss: 0.0035\n",
            "Epoch 943/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7369e-05 - val_loss: 0.0034\n",
            "Epoch 944/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7368e-05 - val_loss: 0.0034\n",
            "Epoch 945/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7367e-05 - val_loss: 0.0034\n",
            "Epoch 946/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7367e-05 - val_loss: 0.0034\n",
            "Epoch 947/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7366e-05 - val_loss: 0.0034\n",
            "Epoch 948/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7366e-05 - val_loss: 0.0034\n",
            "Epoch 949/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7365e-05 - val_loss: 0.0034\n",
            "Epoch 950/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7365e-05 - val_loss: 0.0034\n",
            "Epoch 951/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7364e-05 - val_loss: 0.0034\n",
            "Epoch 952/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7363e-05 - val_loss: 0.0034\n",
            "Epoch 953/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7363e-05 - val_loss: 0.0034\n",
            "Epoch 954/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7363e-05 - val_loss: 0.0034\n",
            "Epoch 955/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7362e-05 - val_loss: 0.0034\n",
            "Epoch 956/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7362e-05 - val_loss: 0.0034\n",
            "Epoch 957/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7361e-05 - val_loss: 0.0034\n",
            "Epoch 958/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7360e-05 - val_loss: 0.0034\n",
            "Epoch 959/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7360e-05 - val_loss: 0.0034\n",
            "Epoch 960/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7359e-05 - val_loss: 0.0033\n",
            "Epoch 961/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7359e-05 - val_loss: 0.0033\n",
            "Epoch 962/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7358e-05 - val_loss: 0.0033\n",
            "Epoch 963/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7357e-05 - val_loss: 0.0033\n",
            "Epoch 964/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7357e-05 - val_loss: 0.0033\n",
            "Epoch 965/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7357e-05 - val_loss: 0.0033\n",
            "Epoch 966/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7356e-05 - val_loss: 0.0033\n",
            "Epoch 967/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7356e-05 - val_loss: 0.0033\n",
            "Epoch 968/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7355e-05 - val_loss: 0.0033\n",
            "Epoch 969/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7354e-05 - val_loss: 0.0033\n",
            "Epoch 970/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7354e-05 - val_loss: 0.0033\n",
            "Epoch 971/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7353e-05 - val_loss: 0.0033\n",
            "Epoch 972/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7353e-05 - val_loss: 0.0033\n",
            "Epoch 973/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7352e-05 - val_loss: 0.0033\n",
            "Epoch 974/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7352e-05 - val_loss: 0.0033\n",
            "Epoch 975/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7351e-05 - val_loss: 0.0033\n",
            "Epoch 976/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7351e-05 - val_loss: 0.0033\n",
            "Epoch 977/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7350e-05 - val_loss: 0.0032\n",
            "Epoch 978/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7350e-05 - val_loss: 0.0032\n",
            "Epoch 979/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7349e-05 - val_loss: 0.0032\n",
            "Epoch 980/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7348e-05 - val_loss: 0.0032\n",
            "Epoch 981/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7348e-05 - val_loss: 0.0032\n",
            "Epoch 982/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7348e-05 - val_loss: 0.0032\n",
            "Epoch 983/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7347e-05 - val_loss: 0.0032\n",
            "Epoch 984/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7346e-05 - val_loss: 0.0032\n",
            "Epoch 985/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7346e-05 - val_loss: 0.0032\n",
            "Epoch 986/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7346e-05 - val_loss: 0.0032\n",
            "Epoch 987/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7345e-05 - val_loss: 0.0032\n",
            "Epoch 988/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7344e-05 - val_loss: 0.0032\n",
            "Epoch 989/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7344e-05 - val_loss: 0.0032\n",
            "Epoch 990/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7343e-05 - val_loss: 0.0032\n",
            "Epoch 991/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7343e-05 - val_loss: 0.0032\n",
            "Epoch 992/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7342e-05 - val_loss: 0.0032\n",
            "Epoch 993/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7342e-05 - val_loss: 0.0032\n",
            "Epoch 994/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7341e-05 - val_loss: 0.0032\n",
            "Epoch 995/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7341e-05 - val_loss: 0.0032\n",
            "Epoch 996/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7340e-05 - val_loss: 0.0032\n",
            "Epoch 997/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7340e-05 - val_loss: 0.0032\n",
            "Epoch 998/1000\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 2.7339e-05 - val_loss: 0.0032\n",
            "Epoch 999/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7339e-05 - val_loss: 0.0032\n",
            "Epoch 1000/1000\n",
            "53/53 [==============================] - 1s 16ms/step - loss: 2.7338e-05 - val_loss: 0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb3110fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "7a5df292-604c-4857-e621-d0b861c1c04e"
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "# plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ],
      "id": "cb3110fa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkfoRgJ0ofTn"
      },
      "source": [
        "Avaliando o modelo"
      ],
      "id": "LkfoRgJ0ofTn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92e490a1"
      },
      "source": [
        "# PREVENDO test_size DIAS\n",
        "\n",
        "preds = []\n",
        "\n",
        "base_teste = np.copy(X_test)\n",
        "\n",
        "for i in range(len(base_teste)):\n",
        "    \n",
        "    y_pred = model.predict(np.array([base_teste[i]]))[0][0]\n",
        "\n",
        "    preds.append(y_pred)\n",
        "\n",
        "    for k in range(len(preds)):\n",
        "        \n",
        "        if k < time_steps:\n",
        "            if(i<len(base_teste)-1):\n",
        "                base_teste[i+1][0][(time_steps-1)-k] = preds[(len(preds)-1)-k]\n",
        "\n",
        "# preds"
      ],
      "id": "92e490a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QguHan-fok5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd28514-fc4f-4368-a4a3-fc78566cc47d"
      },
      "source": [
        "base_teste[0].shape"
      ],
      "id": "QguHan-fok5i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 369)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6O5HjemomRD"
      },
      "source": [
        "# APLICANDO O INVERSE SCALING NOS DADOS\n",
        "\n",
        "dados_pred = {'Quantidade': preds,'d_semana': [0] * test_size,'d_mes': [0] * test_size,'d_ano': [0] * test_size}\n",
        "\n",
        "data_day = data_day.append(pd.DataFrame(data=dados_pred))\n",
        "\n",
        "if(transformar_features):\n",
        "    data_day[feature_names] = scaler.inverse_transform(data_day[feature_names])\n",
        "# feature_names = ['PU','Quantidade', 'Valor','d_semana','d_mes','d_ano']\n",
        "df_dados_real_predito = data_day.tail(test_size*2)\n",
        "\n",
        "dados_real = df_dados_real_predito [0:test_size]['Quantidade'].to_numpy()\n",
        "\n",
        "dados_predito = df_dados_real_predito [test_size:test_size*2]['Quantidade'].to_numpy()\n",
        "\n",
        "\n",
        "# dados_predito"
      ],
      "id": "W6O5HjemomRD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZTh47OWopL7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "bc02f042-d509-4af0-a686-6720f954a5f0"
      },
      "source": [
        "df_real_predito = pd.DataFrame({'real':dados_real,'predito':dados_predito})\n",
        "\n",
        "df_real_predito"
      ],
      "id": "AZTh47OWopL7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real</th>\n",
              "      <th>predito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.933755e+07</td>\n",
              "      <td>3078.982326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.687669e+07</td>\n",
              "      <td>3172.551900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.363394e+07</td>\n",
              "      <td>3101.618457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.349956e+07</td>\n",
              "      <td>3172.429647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.470713e+07</td>\n",
              "      <td>2872.836324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>8.275171e+06</td>\n",
              "      <td>132.199576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>9.286390e+06</td>\n",
              "      <td>152.931700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>8.114514e+06</td>\n",
              "      <td>148.038216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>7.990252e+06</td>\n",
              "      <td>139.999530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>8.824133e+06</td>\n",
              "      <td>155.432400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             real      predito\n",
              "0    6.933755e+07  3078.982326\n",
              "1    6.687669e+07  3172.551900\n",
              "2    6.363394e+07  3101.618457\n",
              "3    6.349956e+07  3172.429647\n",
              "4    5.470713e+07  2872.836324\n",
              "..            ...          ...\n",
              "115  8.275171e+06   132.199576\n",
              "116  9.286390e+06   152.931700\n",
              "117  8.114514e+06   148.038216\n",
              "118  7.990252e+06   139.999530\n",
              "119  8.824133e+06   155.432400\n",
              "\n",
              "[120 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZbQrolyopyN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "66649bf0-99ee-4fe7-93c3-9d34f2aa9aec"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "# plt.plot(range(len(y_train)),y_train, 'g--')\n",
        "plt.plot(range(len(df_real_predito['predito'])),df_real_predito['predito'], 'g--')\n",
        "plt.plot(range(len(df_real_predito['real'])),df_real_predito['real'], 'b')\n",
        "# plt.xlim(0,200)\n",
        "# plt.ylim(40,200)\n",
        "plt.show()"
      ],
      "id": "6ZbQrolyopyN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3RkYbfSoq1k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "367eb000-7d77-4a03-d054-6f2f54157a01"
      },
      "source": [
        "plt.scatter(df_real_predito['real'],df_real_predito['predito'])\n",
        "\n",
        "plt.xlabel('Real')\n",
        "plt.ylabel('Predito')\n",
        "\n",
        "plt.show()\n",
        "print('rmse=',sqrt(mean_squared_error(df_real_predito['real'].array,df_real_predito['predito'].array)))\n",
        "print('mae=',mean_absolute_error(df_real_predito['real'].array,df_real_predito['predito'].array))\n",
        "print('r2=',r2_score(df_real_predito['real'].array,df_real_predito['predito'].array))"
      ],
      "id": "J3RkYbfSoq1k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAc40lEQVR4nO3df5DkdX3n8edrZwcYEBmUDcUO4G5Fajd6BFfngGRTKYGSBX+xRSQh5RmOcJKrQgOR27jr5Q6Ti8VaWyeJSfRuDzAoRkDEdRVLguxWNJ6osyy6WYGDiMIOKpvA8MOdwOzwvj/600vvbHd/u3v6299vT78eVV3T/elvd396Z6ff/f2835/PRxGBmZlZM4uK7oCZmZWfg4WZmWVysDAzs0wOFmZmlsnBwszMMi0uugN5OO6442LZsmVFd8PMrK/s2LHjXyJiSb37FmSwWLZsGRMTE0V3w8ysr0j6SaP7PAxlZmaZHCzMzCyTg4WZmWVysDAzs0wOFmZmlmlBVkOZmfWrLTsn2XTXQzwxNc3S0RHWrVnB2lVjRXfLwcLMrCy27Jxkwx27mJ6ZBWByapoNd+wCKDxgeBjKzKwkNt310IFAUTU9M8umux4qqEcvc7AwMyuJJ6am22rvJQcLM7OSWDo60lZ7LzlYmJmVxLo1KxgZHjqobWR4iHVrVhTUo5c5wW1mlpN2K5uq97kaysxsQHRa2bR21VgpgsNcHoYyM8tBmSubOuFgYWaWgzJXNnXCwcLMLAdlrmzqhIOFmVkOylzZ1AknuM3MclDmyqZOOFiYmeWkrJVNnfAwlJmZZXKwMDOzTA4WZmaWycHCzMwy5R4sJA1J2inpK+n2cknfkfSIpFslHZbaD0+3H0n3L6t5jg2p/SFJa/Lus5mZHawXZxZXAg/U3P4ocF1EvBZ4GrgstV8GPJ3ar0vHIel1wMXA64HzgE9IOrh42czMcpVrsJB0IvA24Pp0W8DZwO3pkJuAten6Bek26f5z0vEXALdExAsR8SjwCHB6nv02M7OD5X1m8RfAHwMvpduvBqYiYn+6vQeoFiGPAY8DpPufSccfaK/zmAMkXS5pQtLE3r17u/0+zMwGWm7BQtLbgScjYkder1ErIjZHxHhEjC9ZsqQXL2lmNjDynMG9GninpLcCRwCvBP4SGJW0OJ09nAhMpuMngZOAPZIWA8cA/1rTXlX7GDMz64HcziwiYkNEnBgRy6gkqLdFxLuB7cC70mGXAF9K17em26T7t0VEpPaLU7XUcuAU4Lt59dvMzA5VxNpQHwRukfTnwE7ghtR+A/AZSY8AT1EJMETEbkm3AT8E9gNXRMTsoU9rZmZ5UeXL+8IyPj4eExMTRXfDzKyvSNoREeP17vMMbjMzy+RgYWZmmRwszMwsk4OFmZllcrAwM7NMDhZmZpbJwcLMzDI5WJiZWSYHCzMzy+RgYWZmmYpYG8rMSm7Lzkk23fUQk1PTDEnMRjA2OsK6NStYu+qQ7WRsADhYmNlBtuycZMMdu5ieqazXOZvWj5ucmmbDHbsAeh4wqsHrialpljpoFcLBwmxAtPqBu+muhw4EirmmZ2bZdNdDPf2gnhu8igxag8w5C7MBUP3AnZyaJnj5A3fLzkP3EXtiarrpc2Xd3231glc1aFnvOFiYDYB2PnCXjo40fa6s+7utUXDqddAadA4WZgOgnQ/cdWtWMDI8VPf4keEh1q1Z0dW+ZWkUnHodtAadg4XZAGjnA3ftqjGuvfBUxtJ9QxIAY6MjXHvhqT3PE9QLXkUErUHnBLfZAFi3ZsVBSWJo/oG7dtVYaZLH1X64GqpYDhZmA6BMH7idlMGWKXgNKgcLswFRhg9cl8H2L+cszKxnXAbbvxwszKxnXAbbvxwszKxnXAbbvxwszKxnXAbbv5zgNrOeKVNVlrXHwcKs5BbaiqtlqMqy9jlYmJWYS02tLJyzMCsxl5paWThYmJWYS02tLDwMZdYj9XIP0DzZu3R0hMk6gcGlpuXWjTxT2XJVDhZmPVAv97Du9u9DwMxLjbctrbcAoICzVi7p7RuwlnUjz1TGXJWHocx6oF7uYWY2DgSKqrn5iLWrxvitN42hmmMC+MKOybq73FnxupFnKmOuysHCrAfayTHMPXb7g3uJOccU/cFhjXUjz1TGXJWHocw61M6YcqPcQ6Nja5Xxg6Pf9HL8v9HvevTI4Xk/R5G5Kp9ZmHWgOqY8OTVN8PKYcqOhoXrLXAwPieFFOqit3tIXXk9pftr9Xc3XujUrGB7SIe3P/9v+ll+zk2VRtuycZPXGbSxffyerN27r+vtzsDDrQLtjyrVblYrKFqWb3nUamy467aC2etuWej2l+en1+P/aVWMcddihgzYzL0XLr1nv/0uzLW17ERA9DGXWgU6Ghhotc9HKLnHg9ZQ6VcQw3jPTM/N+zXaWRWkWELv1/yS3YCHpCOAbwOHpdW6PiGskLQduAV4N7ADeExEvSjoc+DTwJuBfgd+JiB+n59oAXAbMAn8YEXfl1W+zVvR6TNnrKXWuiPH/Xr9mLwJinsNQLwBnR8RpwBuA8ySdCXwUuC4iXgs8TSUIkH4+ndqvS8ch6XXAxcDrgfOAT0g6+JzcrMc8NNQ/ivhd9fo1e5HXyi1YRMXz6eZwugRwNnB7ar8JWJuuX5Buk+4/R5JS+y0R8UJEPAo8ApyeV7/NWtHumLIVp4jfVa9fsxfBKdecRToD2AG8Fvgb4J+BqYjYnw7ZA1T/9caAxwEiYr+kZ6gMVY0B99Y8be1jal/rcuBygJNPPrnr78UGT1a5pYeGyqOMv6tevmYv8lq5BouImAXeIGkU+CKwMsfX2gxsBhgfH587h8msLWVcbsHq8++qIu/g1JPS2YiYArYDvwaMSqoGqROBam3XJHASQLr/GCqJ7gPtdR5j1pJ2a9AbVZdcdev9udSwW+fKuDTGQpRbsJC0JJ1RIGkEeAvwAJWg8a502CXAl9L1rek26f5tERGp/WJJh6dKqlOA7+bVb1t4OqlBb1ZFkvekLquvUcD3DPfeyPPM4gRgu6QfAN8D7o6IrwAfBD4g6REqOYkb0vE3AK9O7R8A1gNExG7gNuCHwNeAK9LwlllLOvnmmVVF4m+uvdUs4HuGe2/klrOIiB8Aq+q0/4g61UwR8W/ARQ2e6yPAR7rdRxsMnXzzrLc0eDuPt+5qFvDr/a5cxtx9nsFtC94xI8NM1ZlR2+ybZ211SaMFAP3NtXeaBXzPcO8NBwtbcGrLKI8ZGea5F/YfcszwImV+86xWl8yttgF/c+21rBnRLmPOnxcStAVl7tj21PQMsy8dWkn9iiMWt/zh4gl4xfOM+eL5zMIWlHpj2/VM7au/0Fsj/uZaLA81Fc/BwhaUVpPOzjf0HwfsYnkYyhaUVoKAhy/M2udgYQtK3R3pFoljjxx2vsFsHjwMZX2jlX2UPbZtlg8HC+sL7SwW57Fts+7zMJT1hQ9v3V13Bu/Vt33fazSZ9YCDhZXelp2TdWdgA8xGeFE/sx5wsLDSy1qwz4v6meXPwcJKr5W5E17UzyxfDhZWeq3MnfAkO7N8tRwsJJ0m6X3pclqenTKrddbKJZnHeJKdWb5aChaSrgQ+C/xSutws6f15dsysavuDe5vef+yRwy6VNctZq/MsLgPOiIhfAEj6KPBt4K/y6phZVVY+4m2/ekKPemI2uFodhhJQW+Q+m9rMcpeVj7j53scO2pPZzLqv1TOLTwHfkfTFdHstcGM+XbJB1Gwpj7NWLuHmex9r+vhmM7rNbP5aOrOIiI8BlwJPpculEXFdnh2zwTF3w6LqB3/1TCErZ1Hl+RZm+Wk1wf2ZiLgvIj6eLjslfSbvztlgqLdhUe0HfztzKDzfwiwfreYsXl97Q9IQ8Kbud8cGUaMP+Gp7O3MoPN/CLB9Ng4WkDZKeA35V0rOSnku3nwS+1JMe2oLX6AM+gNUbt3HWyiWH7lExJIYXHVxj4U2NzPLTNFhExLURcTSwKSJeGRFHp8urI2JDj/poC1y9DYuqJqem+cKOSX7rTWOMjY4c2MBo07tOY9NFpx3U5k2NzPLTtBpK0sqIeBD4vKQ3zr0/Iu7LrWc2MGo3LJqsMyQ1PTPL9gf38q31Zzd8rJnlK6t09mrgvcD/rHNfAIf+9Zp1oLph0fL1dxJ17nfi2qxYTYNFRLw3/TyrN92xQbd0dKTu2YUT12bFyhqGurDZ/RFxR3e7Y4Nu3ZoVB22fCk5cm5VB1jDUO9LPXwJ+HdiWbp8F/F/AwcK6qjZ/UW82t5kVI2sY6lIASX8PvC4ifppunwD8be69s4FUzV+YWXm0ujbUSdVAkfwcODmH/tgC1mz9JzMrt1aDxT2S7gI+l27/DvD1fLpkC1F1/adqLsIL/5n1l1YXEnwf8L+A09Jlc0R48yNrWdb6T2ZWbq2eWQDcBzwXEV+XdKSkoyPiubw6ZgtL1vpPZlZura46+17gduB/p6YxYEtenbKFp9E8Cc+fMOsPra46ewWwGngWICIeplJOa9aSeus/ef6EWf9oNVi8EBEvVm9IWgx1V2Uwa+iI4Zf/u42ODHvhP7M+0mqw+AdJHwJGJL0F+Dzw5fy6ZQtJtRLq6X0zB9pe2P9SgT0ys3a1Giw+COwFdgF/AHwV+JNmD5B0kqTtkn4oabekK1P7qyTdLenh9PPY1C5JH5f0iKQf1K5yK+mSdPzDki7p5I1acRpVQn146+6CemRm7coMFmlXvAci4v9ExEUR8a50PWsYaj9wdUS8DjgTuELS64D1wD0RcQpwT7oNcD5wSrpcDnwyvf6rgGuAM4DTgWuqAcb6Q6OKp6npmQP7bJtZuWUGi4iYBR6S1NaM7Yj4aXW/i1Ri+wCVKqoLgJvSYTcBa9P1C4BPR8W9wGhaVmQNcHdEPBURTwN3A+e10xcrVrOKJ8+zMOsPrQ5DHQvslnSPpK3VS6svImkZsAr4DnB8zdIhPwOOT9fHgMdrHrYntTVqn/sal0uakDSxd+/eVrtmPdCs4mlyaprl6+9k9cZtPsswK7FWJ+X9t05fQNIrgC8AV0XEs9LL+yZHREjqSlVVRGwGNgOMj4+7UqtE1q4a40+/vPugBHetwMt/mJVd0zMLSUdIugq4CFgJfCsi/qF6yXpyScNUAsVna/a++HkaXqquXvtkap8ETqp5+ImprVG79ZFr3vH6hvtsV3n5D7PyyhqGugkYp1IFdT71t1etS5VTiBuoJMc/VnPXVqBa0XQJ8KWa9t9LVVFnAs+k4aq7gHMlHZsS2+emNusja1eNce2FpzI2OoKaHOflP8zKSc2KmiTtiohT0/XFwHcj4o0NH3DwY38D+CaVQFMtqv8QlbzFbVSWOP8J8NsR8VQKLn9NJXm9D7g0IibSc/1+eizARyLiU81ee3x8PCYmJlrpphVk9cZtdbdPHZJ4KcJLmJsVQNKOiBivd19WzuLAIHNE7K/NN2SJiH+Ehl8iz6lzfFBZVqTec90I3Njyi1vp1ds+FWA2fXlxDsOsXLKCxWmSnk3XRWUG97PpekTEK3PtnfW9Rhsezd0+dZF0IFBUVXMYDhZmxcvaVrV5RtKsiawNj2qDxvL1d9Z9DucwzMqh1XkWZm1rZ8MjL2FuVm4OFpabRmcF9SbieQlzs3JrZ6c8s7YsHR2pW/EEjSfi1ctvmFnxmpbO9iuXzpbD3JxFI2OjI3xr/dk96pWZNTKf0lmzjs09W2j0tcRJbLPyc7CwXNVWPDWaiOcktln5OcFtPeMktln/8pmF9YyT2Gb9ywluK0Sjmd1mVhwnuK1UsmZ2m1n5OGdhPdfOzG4zKwcHC+u5RqWyLqE1Ky8PQ1lP1OYo6q0wCy6hNSszBwvL3dwcRb1A4RJas3JzsLDc1ctRgHfFM+snDhaWu0a5iJcieHTj23rcGzPrhBPcljvvVWHW/xwsLHde5sOs/3kYytrW7uxrL/Nh1v8cLKwtnc6+rl191sz6j4ehrC2efW02mBwsrC2efW02mBwsrC3HjAy31W5mC4ODhbVFaq/dzBYGBwtry9S+mbbazWxhcLCwtniCndlgcrCwtniCndlg8jwLa4sn2JkNJgcLy1Rvxva31p9ddLfMrIccLKwp75dtZuCchWXwjG0zAwcLy+AZ22YGDhbWxJadkyxqMNvOpbJmg8XBwuqq5iq8X7aZgRPcC1a7e07M1Wzf7GsvPNXJbbMBk9uZhaQbJT0p6Z9q2l4l6W5JD6efx6Z2Sfq4pEck/UDSG2sec0k6/mFJl+TV34WkelYwOTVN8HIF05adk3WPXb1xG8vX38nqjdsOHNNs32wHCrPBk+cw1N8C581pWw/cExGnAPek2wDnA6eky+XAJ6ESXIBrgDOA04FrqgHGGmu1gqlZUPGyHmZWK7dgERHfAJ6a03wBcFO6fhOwtqb901FxLzAq6QRgDXB3RDwVEU8Dd3NoALI5Gp0VTM5pbxZUvKyHmdXqdYL7+Ij4abr+M+D4dH0MeLzmuD2prVH7ISRdLmlC0sTevXu72+s+0+jbv+CgoahmZbFrV41x7YWnMjY6goCx0RHnKswGWGEJ7ogISYeW2nT+fJuBzQDj4+Nde95+tG7NCv7o1vuZ+48QVM4mqh/4S0dHDjnbqLaD9802s5f1+szi52l4ifTzydQ+CZxUc9yJqa1RuzWxdtXYIYGiqvZswkNNZtaqXgeLrUC1oukS4Es17b+XqqLOBJ5Jw1V3AedKOjYlts9NbZZhrIUEtYeazKxVuQ1DSfoc8GbgOEl7qFQ1bQRuk3QZ8BPgt9PhXwXeCjwC7AMuBYiIpyT9D+B76bg/i4i5SXOrY92aFQctAAiVnMVZK5ccdJyHmsysFYo6M3T73fj4eExMTBTdjcJUJ+TVy0eMDA/57MHM6pK0IyLG693n5T4WmNq5E/V4xVgz64SDxQLTaJmOWl4x1sza5bWh+tzcNaAanVHU8ixsM2uXg0Ufq7eLnaBh2SxUktwujTWzdnkYqo/VG3LKKlcIvB2qmbXPwaKPNcs91N+yqPH8CzOzZhws+liz3MPokcOenW1mXeNg0ceaffBP7Zvx7Gwz6xonuBeopaMjnp1tZl3jM4s+1mxy3b4X99fdGc/MrBMOFn2sWYL76X0zDbdSNTNrl4NFH8uaXDc9M8uHt+7uUW/MbCFzsOhj9fajmGtqesZnF2Y2b05w96HaJT5Gjxzm8MWLmJqeaXh87e54ZmadcLDoM3OX+Hh6XyVIHHXYEL94sf4Cgl440Mzmy8NQfabRqrKNAgV44UAzmz8Hiz6TdZYwd5kPz9o2s25wsOgzx4wMN70/wLO2zazrnLPoM2q0QmCNs1Yu4c/Xnpp/Z8xsYPjMos9M7Wtc9VT12Xsfc7msmXWVg0VJbdk5yeqN21i+/k5Wb9x24MO/lWR10HwpEDOzdjlYlFC1PHZyapqgsgPeVbfez7L1d7Lvxf0ML8oei3K5rJl1k4NFCTUqj4U0r0IwmpHodrmsmXWTg0UJZZ0VzMwGU9MzjI2OsPqXX+VyWTPLnYNFCbV6VjA5Nc19jz3Du8882eWyZpYrl84WpLq+0+TUNEMSsxGMjY6wbs0K1q1ZwR/dej/RwvNMz8yy/cG9fGv92bn32cwGl88sClCbwAaYjUpYmJyaZsMduwB495knt/x8TmabWd58ZtFjW3ZOcvVt3z8QIOaanpnlqlvvZ2x0hCOHF7Fv5qXM53Qy28zy5mDRI1t2TvJfv7ir6YJ/tSanphkeEsOLxMxLjQeknMw2s15wsMjZn2zZxc33PtbRY2dmg2OPHObIwxbzxNQ0S0dHOGvlErY/uPfA7XVrVjiZbWa5c7DoUO0GRNUPbYAPb93ddCOidk3tm2Hnfz+3a89nZtYJB4s6OhkyuurW+3Ppi/MRZlYGDhY1tuyc7PqZwXw4H2FmZeFgkczdrrRoY85HmFmJOFgkzdZj6qWR4SHPwDaz0nGwSHo9sU1UlhIfHRlGqiSyXd1kZmXlYJEsHR05MKO62155+BBHjxzmclcz61sOFsm6NSvmlbM4/ujDWDw0VHetJwcGM+t3fRMsJJ0H/CUwBFwfERu7+fzVD/S5i/vVMyTxu2ec5H2uzWxg9EWwkDQE/A3wFmAP8D1JWyPih918nbWrxnwWYGZWR7+sOns68EhE/CgiXgRuAS4ouE9mZgOjX4LFGPB4ze09qe0ASZdLmpA0sXfv3p52zsxsoeuXYJEpIjZHxHhEjC9ZsqTo7piZLSj9EiwmgZNqbp+Y2szMrAf6JVh8DzhF0nJJhwEXA1sL7pOZ2cBQNCgPLRtJbwX+gkrp7I0R8ZEmx+4FftKrvgHHAf/Sw9fLg99DeSyE9+H3UA7tvofXRETdcfy+CRZlJmkiIsaL7sd8+D2Ux0J4H34P5dDN99Avw1BmZlYgBwszM8vkYNEdm4vuQBf4PZTHQngffg/l0LX34JyFmZll8pmFmZllcrAwM7NMDhbzIOlGSU9K+qei+9IpSSdJ2i7ph5J2S7qy6D61S9IRkr4r6fvpPfxp0X3qlKQhSTslfaXovnRC0o8l7ZJ0v6SJovvTKUmjkm6X9KCkByT9WtF9aoekFel3UL08K+mqeT2ncxadk/SbwPPApyPi3xXdn05IOgE4ISLuk3Q0sANY2+3l3/MkScBREfG8pGHgH4ErI+LegrvWNkkfAMaBV0bE24vuT7sk/RgYj4i+nswm6SbgmxFxfVo14siImCq6X51IWzxMAmdERMeTlX1mMQ8R8Q3gqaL7MR8R8dOIuC9dfw54gDkr+pZdVDyfbg6nS999C5J0IvA24Pqi+zLIJB0D/CZwA0BEvNivgSI5B/jn+QQKcLCwGpKWAauA7xTbk/al4Zv7gSeBuyOi794DleVs/hh4qeiOzEMAfy9ph6TLi+5Mh5YDe4FPpSHB6yUdVXSn5uFi4HPzfRIHCwNA0iuALwBXRcSzRfenXRExGxFvoLIi8emS+mpYUNLbgScjYkfRfZmn34iINwLnA1ekodp+sxh4I/DJiFgF/AJYX2yXOpOG0N4JfH6+z+VgYaRx/i8An42IO4ruz3yk4YLtwHlF96VNq4F3pjH/W4CzJd1cbJfaFxGT6eeTwBep7HLZb/YAe2rOTm+nEjz60fnAfRHx8/k+kYPFgEvJ4RuAByLiY0X3pxOSlkgaTddHqOzV/mCxvWpPRGyIiBMjYhmVYYNtEfEfCu5WWyQdlYokSMM25wJ9VykYET8DHpe0IjWdA/RNwcccv0sXhqCgcrplHZL0OeDNwHGS9gDXRMQNxfaqbauB9wC70pg/wIci4qsF9qldJwA3paqPRcBtEdGXpad97njgi5XvHywG/i4ivlZslzr2fuCzaRjnR8ClBfenbSlgvwX4g648n0tnzcwsi4ehzMwsk4OFmZllcrAwM7NMDhZmZpbJwcLMrM+1s6ippOtqFhj8f5JaWsrE1VBmXSJpFthFpWz0UeA9nawpJOk/UlmM733d7aEtVJ0uairp/cCqiPj9rGN9ZmHWPdMR8Yb0x/oUcEXRHbLBUG9RU0m/LOlraZ2ub0paWeehLU/ac7Awy8e3Sav3NvqjlfQOSd9Ji9V9XdLxhfbYFprNwPsj4k3AfwE+UXunpNdQWTRxWytP5hncZl2WZpKfQ1rimsof7X+OiIclnUHlj/ZsKvtunBkRIek/UVlx9uoi+mwLS1oY9NeBz6cZ9QCHzznsYuD2iJht5TkdLMy6ZyQtmTJGZV+QuzP+aE8Ebk0bUB1GJc9h1g2LgKm0EnMjF9PGUKmHocy6Zzr9cb4GEJU/xAN/tDWXX0nH/xXw1xFxKpX1e44opNe24KRtBh6VdBFUFgyVdFr1/jQUeiyV4dKWOFiYdVlE7AP+kMqQ0j4a/9EeQ2W7S4BLet5RWzDSoqbfBlZI2iPpMuDdwGWSvg/sBi6oecjFwC3RRjmsS2fNukTS8xHxiprbXwZuo5Kb+CSV1XGHqfyR/pmkC4DrgKepJBn/fUS82aWzVkYOFmZmlsnDUGZmlsnBwszMMjlYmJlZJgcLMzPL5GBhZmaZHCzMzCyTg4WZmWX6/xLdkOHI/l2LAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmse= 27242974.52430226\n",
            "mae= 22357722.960286867\n",
            "r2= -2.0624537342774865\n"
          ]
        }
      ]
    }
  ]
}